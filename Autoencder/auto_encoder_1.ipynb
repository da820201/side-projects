{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auto_encoder_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSUqfSLfGv4B",
        "colab_type": "code",
        "outputId": "e28f7155-6e14-40fd-8f73-f2d2ff3c96cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSazWrTUSrtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdwkbvCEG96I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "fn = glob.glob(\"./drive/My Drive/Spliter/class_training/*\")\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgS1_b7MGrAU",
        "colab_type": "code",
        "outputId": "f027b600-5257-424b-e807-60851d767f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "import sys\n",
        "\n",
        "py_version = '.'.join([str(i) for i in list(sys.version_info[:3])])\n",
        "tf_version = int(''.join(str(tf.__version__).split('.')[:2]))\n",
        "_log = __import__('tensorflow.compat.v1', fromlist=['log'], level=0) if tf_version > 15 else __import__('tensorflow',\n",
        "                                                                                                        fromlist=[\n",
        "                                                                                                            'log'],\n",
        "                                                                                                        level=0)\n",
        "\n",
        "BN = BatchNormalization(beta_initializer=tf.zeros_initializer(),\n",
        "                                    gamma_initializer=tf.ones_initializer()\n",
        "                                    , moving_mean_initializer=tf.zeros_initializer(),\n",
        "                                    moving_variance_initializer=tf.ones_initializer())\n",
        "\n",
        "\n",
        "class Self_Attention(Layer):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        self.output_dim = output_dim\n",
        "        super(Self_Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(name='kernel',\n",
        "                                      shape=(3, input_shape[2], self.output_dim),\n",
        "                                      initializer='uniform',\n",
        "                                      trainable=True)\n",
        "\n",
        "        super(Self_Attention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        WQ = K.dot(x, self.kernel[0])\n",
        "        WK = K.dot(x, self.kernel[1])\n",
        "        WV = K.dot(x, self.kernel[2])\n",
        "\n",
        "        QK = K.batch_dot(WQ, K.permute_dimensions(WK, [0, 2, 1]))\n",
        "        QK = QK / (64 ** 0.5)\n",
        "        QK = K.softmax(QK)\n",
        "\n",
        "        V = K.batch_dot(QK, WV)\n",
        "        return V\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[1], self.output_dim)\n",
        "\n",
        "\n",
        "def res_conv2D_block(input_: Model or Layer, filters: int, kernel_size: tuple or list, padding: str = 'SAME',\n",
        "                     strides: tuple or list = (1, 1), D_forge: int = 2, repeat_T: int = 1, name_scope: int = 0,\n",
        "                     activation: str or Layer = LeakyReLU(0.3)):\n",
        "    for it in range(repeat_T):\n",
        "        model = input_\n",
        "        for i in range(D_forge):\n",
        "            model = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
        "                           padding=padding, name=\"res_Conv2D_{}_{}_{}\".format(name_scope, it, i))(model)\n",
        "        model = activation(model)\n",
        "        input_ = Add()([model, input_])\n",
        "        input_ = BatchNormalization(beta_initializer=tf.zeros_initializer(),\n",
        "                                    gamma_initializer=tf.ones_initializer()\n",
        "                                    , moving_mean_initializer=tf.zeros_initializer(),\n",
        "                                    moving_variance_initializer=tf.ones_initializer())(input_)\n",
        "    return input_\n",
        "\n",
        "\n",
        "def res_Dense_block(input_: Model or Layer, D_forge: int = 2, repeat_T: int = 1, name_scope: int = 0,\n",
        "                    activation: str or Layer = LeakyReLU(0.3), target_block: object or Layer = Dense):\n",
        "    target_block = target_block if type(target_block) is Layer else Dense\n",
        "    for it in range(repeat_T):\n",
        "        model = input_\n",
        "        for i in range(D_forge):\n",
        "            model = target_block(int(model.get_shape()[-1]), activation='linear',\n",
        "                                 name=\"res_Dense_{}_{}_{}\".format(name_scope, it, i))(model)\n",
        "        model = activation(model)\n",
        "        input_ = Add()([model, input_])\n",
        "        input_ = BatchNormalization(momentum=0.9)(input_)\n",
        "        input_ = Dropout(0.25)(input_)\n",
        "    return input_\n",
        "\n",
        "\n",
        "class Self_define_loss(object):\n",
        "    def __init__(self, cls_num:int=7):\n",
        "        self.cls_num = cls_num\n",
        "\n",
        "    def mycrossentropy(self, y_true, y_pred, e=0.1):\n",
        "        loss1 = K.categorical_crossentropy(y_true, y_pred)\n",
        "        loss2 = K.categorical_crossentropy(K.ones_like(y_pred)/self.cls_num, y_pred)\n",
        "        return (1-e)*loss1 + e*loss2\n",
        "\n",
        "    def multi_category_focal_loss2_fixed(self, y_true, y_pred):\n",
        "        epsilon = 1.e-7\n",
        "        gamma = 2.\n",
        "        alpha = tf.constant(0.5, dtype=tf.float32)\n",
        "\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "        alpha_t = y_true * alpha + (tf.ones_like(y_true) - y_true) * (1 - alpha)\n",
        "        y_t = tf.multiply(y_true, y_pred) + tf.multiply(1 - y_true, 1 - y_pred)\n",
        "        ce = log(y_t)\n",
        "        weight = tf.pow(tf.subtract(1., y_t), gamma)\n",
        "        fl = tf.multiply(tf.multiply(weight, ce), alpha_t)\n",
        "        loss = tf.reduce_mean(fl)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def root_mean_squared_error(self, y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "\n",
        "\n",
        "def res_Self_attention_block(input_: Model or Layer, D_forge: int = 2, repeat_T: int = 1, name_scope: int = 0):\n",
        "    for it in range(repeat_T):\n",
        "        model = input_\n",
        "        for i in range(D_forge):\n",
        "            model = Self_Attention(int(model.get_shape()[-1]), name=\"res_Self_attention_{}_{}_{}\".format(name_scope, it, i))(model)\n",
        "        input_ = Add()([model, input_])\n",
        "        input_ = BatchNormalization(momentum=0.9)(input_)\n",
        "        input_ = Dropout(0.25)(input_)\n",
        "    return input_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHj1BQNeHN4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical, plot_model\n",
        "\n",
        "configs = {\n",
        "    'fit_generator': False,\n",
        "    'allow_growth': True,\n",
        "    'batch_size': 50,\n",
        "}\n",
        "\n",
        "py_version = '.'.join([str(i) for i in list(sys.version_info[:3])])\n",
        "tf_version = int(''.join(str(tf.__version__).split('.')[:2]))\n",
        "\n",
        "_log = __import__('tensorflow.compat.v1', fromlist=['log'], level=0) if tf_version > 15 else __import__('tensorflow',\n",
        "                                                                                                        fromlist=[\n",
        "                                                                                                            'log'],\n",
        "                                                                                                        level=0)\n",
        "log = _log.log\n",
        "\n",
        "fn = glob.glob(\"./Drive/Spliter/*\")\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "label_name = []\n",
        "\n",
        "\n",
        "def detect_data_path(fn: glob.glob or None) -> dict:\n",
        "    result = {}\n",
        "    folder_path = [i.replace('\\\\', '/') if \" \" in str(i).split('\\\\')[-1] else None for i in fn]\n",
        "    if all([True if i is None else False for i in folder_path]):\n",
        "        folder_path = [i.replace('\\\\', '/') for i in fn]\n",
        "        print(folder_path)\n",
        "    else:\n",
        "        [folder_path.remove(None) if i is None else i for i in folder_path.copy()]\n",
        "    file_name = [str(i).split('/')[-1].split('\\\\')[-1] if '\\\\' in str(i).split('/')[-1] else str(i).split('/')[-1] for i\n",
        "                 in folder_path]\n",
        "\n",
        "    for it, main_key in enumerate(file_name):\n",
        "        data_file_path = [i.replace('\\\\', '/') for i in glob.glob(f\"{folder_path[it]}/*\")]\n",
        "        data_file_name = [str(i).split('/')[-1] for i in data_file_path]\n",
        "        temp_dict = {data_file_name[i]: m for i, m in enumerate(data_file_path)}\n",
        "        temp_dict.update({'stock_id': str(folder_path[it]).split('/')[-1].split(' ')[0]})\n",
        "        result.update({main_key: temp_dict})\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def read_data(stock: str, use_set_remove: bool = True,\n",
        "              data_main_floder: str or glob.glob or None = None) -> pd.DataFrame:\n",
        "    data_dict = detect_data_path(data_main_floder)\n",
        "    df = pd.DataFrame(data_dict)\n",
        "    x = {df[i]['stock_id']: i for i in df} if stock.isdigit() else None\n",
        "    stock = x[stock] if x is not None and stock in x else stock\n",
        "    x_df, y_df = [[pd.read_csv(df[i]['Tech_I.csv'], header=0) for i in list(df.keys())],\n",
        "                  [pd.read_csv(df[i]['y_train_change_class.csv'], header=0) for i in\n",
        "                   list(df.keys())]] if stock in [\n",
        "        \"all\", \"ALL\"] else [pd.read_csv(df[stock]['Tech_I.csv'], header=0),\n",
        "                            pd.read_csv(df[stock]['y_train_change_class.csv'], header=0)]\n",
        "\n",
        "    x_df, y_df = [pd.concat(x_df, axis=0), pd.concat(y_df, axis=0)] if stock in [\"all\", \"ALL\"] else (x_df, y_df)\n",
        "\n",
        "    if use_set_remove:\n",
        "        x_df_c, y_df_c = list(x_df.columns), list(y_df.columns)\n",
        "        same_col = set(x_df_c)\n",
        "        same_col.intersection_update(y_df_c)\n",
        "    else:\n",
        "        same_col = []\n",
        "    if len(same_col) is not 0: y_df.drop(str(same_col.pop()), axis=1)\n",
        "    result = pd.concat([x_df, y_df], axis=1, join='inner')\n",
        "    return result\n",
        "\n",
        "\n",
        "def train_test(data: pd.DataFrame, batch_size, timestep, feature_dim, FD, drop_list: list or None = None,\n",
        "               label_name: list or None = None, use_gaussian: bool = True, label_num: list = [], to_cat: bool = True,\n",
        "               preds: bool = False):\n",
        "    def de_shape(feature: np.array, batch_size=None, timestep=None, feature_dim=None, FD=None):\n",
        "        shape_data = [-1 if m is None and i is 0 else m for i, m in enumerate([batch_size, timestep, feature_dim, FD])]\n",
        "        [shape_data.remove(None) if i is None else i for i in shape_data.copy()]\n",
        "        feature = feature.reshape(shape_data)\n",
        "        return feature\n",
        "\n",
        "    def drop_dim(data: pd.DataFrame, drop_list):\n",
        "        data = data.drop(drop_list, axis=1) if isinstance(drop_list, list) else data.drop([\"date\"], axis=1)\n",
        "        return data\n",
        "\n",
        "    def find_labels():\n",
        "        res = -1 if label_name is None else [list(data.keys()).index(i) for i in label_name]\n",
        "        res.sort() if isinstance(res, list) else None\n",
        "        return res[0] if isinstance(res, list) else res\n",
        "\n",
        "    def gaussian_labels(D: pd.DataFrame, label_num: list, stage: list or None = None, deg: float = 1.0):\n",
        "        stage = [0.63, 1] if stage is None else stage\n",
        "        result = []\n",
        "\n",
        "        for i, m in enumerate(label_num):\n",
        "            label = list(to_categorical(pd.DataFrame(D)[i], num_classes=m)) if to_cat is True else list(\n",
        "                pd.DataFrame(D)[i])\n",
        "\n",
        "            if use_gaussian:\n",
        "                res = []\n",
        "                for ic in label:\n",
        "                    item = list(ic)\n",
        "                    _index = item.index(1)\n",
        "                    item[_index] = deg\n",
        "                    for it in range(1, stage[1] + 1):\n",
        "                        if _index - it >= 0:\n",
        "                            item[_index - it] = stage[0] ** (it)\n",
        "                        if _index + it < m:\n",
        "                            item[_index + it] = stage[0] ** (it)\n",
        "                    res.append(item)\n",
        "                result.append(list(de_shape(np.array(res), batch_size, m)))\n",
        "            else:\n",
        "                result.append(list(label))\n",
        "\n",
        "        return result\n",
        "\n",
        "    def train_test(data, row: float or None = None):\n",
        "        row = round(0.85 * data.shape[0]) if row is None else row\n",
        "        if preds:\n",
        "            return np.array(data[:int(row)]), np.array(data[-1:])\n",
        "        else:\n",
        "            return np.array(data[:int(row)]), np.array(data[int(row):])\n",
        "\n",
        "    def normal_categorical(D: pd.DataFrame, label_num: list or None = None) -> list:\n",
        "        label_len = np.array(D).shape[-1]\n",
        "        if label_num is None: label_num = []\n",
        "        result = []\n",
        "        for i in range(len(label_num), label_len):\n",
        "            if to_cat:\n",
        "                max_label_num = int(max(pd.DataFrame(D)[i]) + 1)\n",
        "                result.append(list(to_categorical(pd.DataFrame(D)[i], num_classes=max_label_num)))\n",
        "            else:\n",
        "                result.append(list(pd.DataFrame(D)[i]))\n",
        "        return result\n",
        "\n",
        "    data = drop_dim(data, drop_list)\n",
        "    labels_cl = find_labels()\n",
        "\n",
        "    train, test = train_test(data)\n",
        "\n",
        "    x_train = train[:, :labels_cl]\n",
        "    label_train = train[:, labels_cl:]\n",
        "\n",
        "    x_test = test[:, :labels_cl]\n",
        "    label_test = test[:, labels_cl:]\n",
        "\n",
        "    feature_train = de_shape(x_train, batch_size, timestep, feature_dim, FD)\n",
        "    feature_test = de_shape(x_test, batch_size, timestep, feature_dim, FD)\n",
        "    if use_gaussian:\n",
        "        # label_num= [label_num, label_num, label_num=39]\n",
        "        label_train_ = gaussian_labels(label_train, label_num=label_num)\n",
        "        label_test_ = gaussian_labels(label_test, label_num=label_num)\n",
        "        if to_cat:\n",
        "            label_test_.append(list(to_categorical(pd.DataFrame(label_test)[3], num_classes=3)))\n",
        "            label_train_.append(list(to_categorical(pd.DataFrame(label_train)[3], num_classes=3)))\n",
        "        else:\n",
        "            label_test_.append(list(pd.DataFrame(label_test)[3]))\n",
        "            label_train_.append(list(pd.DataFrame(label_train)[3]))\n",
        "    else:\n",
        "        label_train_ = normal_categorical(label_train, label_num)\n",
        "        label_test_ = normal_categorical(label_test, label_num)\n",
        "\n",
        "    return feature_train, [np.array(i) for i in label_train_], feature_test, [np.array(i) for i in label_test_]\n",
        "\n",
        "\n",
        "def data_l(stock_id, target, csv_floder_path=None, preds: bool = False, label_name: list = []):\n",
        "    result = read_data(stock_id, data_main_floder=csv_floder_path)\n",
        "    drop_list = [\"date\"]\n",
        "    re_dict = {\n",
        "            'high': '0',\n",
        "            'low': '1',\n",
        "            'close': '2',\n",
        "            'trend': '3'\n",
        "        }\n",
        "    # re_dict = {m: i for i, m in enumerate(label_name)}\n",
        "    feature_train, train_labels, feature_test, test_labels = train_test(result, -1, None, 900, None,\n",
        "                                                                        drop_list,\n",
        "                                                                        label_name=label_name,\n",
        "                                                                        use_gaussian=False,\n",
        "                                                                        label_num=[],\n",
        "                                                                        to_cat=True, preds=preds)\n",
        "    ret = {str(i): [m, test_labels[i]] for i, m in enumerate(train_labels)}\n",
        "    result = ret[re_dict[target]]\n",
        "    return feature_train, result[0], feature_test, result[1]\n",
        "\n",
        "\n",
        "def odd_data_l(stock_id, target):\n",
        "    dic = fn\n",
        "    result = read_data(stock_id, data_main_floder=dic)\n",
        "    drop_list = [\"date\"]\n",
        "    label_name = ['high_change_class', 'low_change_class', 'close_change_class', 'close_change_class3']\n",
        "    feature_train, [high_label_train, low_label_train, close_label_train, trend_label_train], feature_test, [\n",
        "        high_label_test, low_label_test, close_label_test, trend_label_test] = train_test(result, -1, None, 900, None,\n",
        "                                                                                          drop_list,\n",
        "                                                                                          label_name,\n",
        "                                                                                          use_gaussian=False,\n",
        "                                                                                          label_num=[],\n",
        "                                                                                          to_cat=True)\n",
        "    ret = {\n",
        "        'ALL': [[high_label_train, low_label_train, close_label_train, trend_label_train],\n",
        "                [high_label_test, low_label_test, close_label_test, trend_label_test]],\n",
        "        'high': [high_label_train, high_label_test],\n",
        "        'low': [low_label_train, low_label_test],\n",
        "        'close': [close_label_train, close_label_test],\n",
        "        'trend': [trend_label_train, trend_label_test],\n",
        "    }\n",
        "\n",
        "    result = ret[target]\n",
        "\n",
        "    return feature_train, result[0], feature_test, result[1]\n",
        "\n",
        "\n",
        "def auto_multilabels_to_one(em_len, features: list, labels: list, output_dim: int, define_loss='mean_squared_error'):\n",
        "    split_time = round(int(np.array(features[0]).shape[-1]) / em_len)\n",
        "\n",
        "    Feature_train_ = [features[0][:, i * split_time:i * split_time + split_time] for i in range(em_len)]\n",
        "    Feature_test_ = [features[1][:, i * split_time:i * split_time + split_time] for i in range(em_len)]\n",
        "\n",
        "    Label_train = {'out_{}'.format(i): np.array(m).reshape([-1, split_time, 1]) for i, m in enumerate(Feature_train_)}\n",
        "    Feature_train = {'intput_{}'.format(i): np.array(m).reshape([-1, split_time, 1]) for i, m in\n",
        "                     enumerate(Feature_train_)}\n",
        "\n",
        "    Label_test = {'out_{}'.format(i): np.array(m).reshape([-1, split_time, 1]) for i, m in enumerate(Feature_test_)}\n",
        "    Feature_test = {'intput_{}'.format(i): np.array(m).reshape([-1, split_time, 1]) for i, m in\n",
        "                    enumerate(Feature_test_)}\n",
        "\n",
        "    Loss = {'out_{}'.format(i): define_loss for i in range(em_len)}\n",
        "    Loss_weights = {'out_{}'.format(i): 1. for i in range(em_len)}\n",
        "    # --------------------------------------------------------------------------------------------------------------#\n",
        "    ouput_name = 'final_output'\n",
        "    Label_train.update({ouput_name: np.array(labels[0].reshape([-1, output_dim]))})\n",
        "    Label_test.update({ouput_name: np.array(labels[1].reshape([-1, output_dim]))})\n",
        "    Loss.update({ouput_name: 'categorical_crossentropy'})\n",
        "    Loss_weights.update({ouput_name: 1.})\n",
        "\n",
        "    # --------------------------------------------------------------------------------------------------------------#\n",
        "    return Feature_train, Label_train, Feature_test, Label_test, Loss, Loss_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpWIHLSND4jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "def train_mode(target: str, stock_id, model, output_dim, define_loss, input_num, label_name, data_path):\n",
        "    feature_train, label_train, feature_test, label_test = data_l(stock_id, target,label_name=label_name,preds=False,\n",
        "                                                                  csv_floder_path=data_path)\n",
        "    FS = [feature_train, feature_test]\n",
        "    LS = [label_train, label_test]\n",
        "    Feature_train, Label_train, Feature_test, Label_test, Loss, Loss_weights = auto_multilabels_to_one(input_num, FS,\n",
        "                                                                                                       LS, output_dim,\n",
        "                                                                                                       define_loss=define_loss)\n",
        "    opt = Adam(1e-5)\n",
        "    model.compile(optimizer=opt, loss=Loss, loss_weights=Loss_weights, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model, [Feature_train, Label_train, Feature_test, Label_test], [feature_train, label_train, feature_test,\n",
        "                                                                           label_test]\n",
        "\n",
        "\n",
        "def fit_model(epochs: int = 10, batch_size: int = 50, define_loss='categorical_crossentropy',\n",
        "              reduce_lr: bool = True,\n",
        "              is_train: bool = True, input_num=0, data_path='',label_name=[],save_path=''):\n",
        "    callbacks = []\n",
        "    result = train_mode(target='close', stock_id='2330 台積電', model=model_train, output_dim=output_dim,\n",
        "                        define_loss=define_loss, input_num=input_num,label_name=label_name,data_path=data_path)\n",
        "\n",
        "    if is_train:\n",
        "        callbacks.append(\n",
        "            ModelCheckpoint(f'.{save_path}.'+'{epoch:05d}-{val_loss:.5f}.hdf5', save_best_only=True))\n",
        "\n",
        "    if reduce_lr:\n",
        "        callbacks.append(ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=50, min_lr=0.00000001, verbose=1))\n",
        "\n",
        "    result[0].fit(result[1][0], result[1][1], epochs=epochs, batch_size=batch_size, callbacks=callbacks,\n",
        "                  validation_split=0.01, verbose=1)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOJwtmT5V9ZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def layers(input_target):\n",
        "    conv1D_list = [Conv1D(32, 1, name='Conv1D_0_{}'.format(i))(m) for i, m in enumerate(input_target)]\n",
        "    res_dense = [res_Dense_block(m, name_scope='0_{}'.format(i)) for i, m in enumerate(conv1D_list)]\n",
        "    BN = [BatchNormalization()(m) for i, m in enumerate(res_dense)]\n",
        "    res_dense = [res_Dense_block(m, name_scope='1_{}'.format(i)) for i, m in enumerate(BN)]\n",
        "    mid_layer = [TimeDistributed(Dense(128, activation='linear', name='mid_Dense_{}'.format(i)))(m) for i, m in\n",
        "                 enumerate(res_dense)]\n",
        "    res_dense = [res_Dense_block(m,name_scope='2_{}'.format(i)) for i, m in enumerate(mid_layer)]\n",
        "    BN = [BatchNormalization()(m) for i, m in enumerate(res_dense)]\n",
        "    res_dense = [res_Dense_block(m,name_scope='3_{}'.format(i)) for i, m in enumerate(BN)]\n",
        "    conv1D_list = [Conv1D(32, 1, name='Conv1D_1_{}'.format(i))(m) for i, m in enumerate(res_dense)]\n",
        "\n",
        "    auto_encoder_out = [TimeDistributed(Dense(1, activation='linear'), name='out_{}'.format(i))(m) for i, m in\n",
        "                        enumerate(conv1D_list)]\n",
        "    return auto_encoder_out, mid_layer\n",
        "\n",
        "\n",
        "def output_layer(input_target, output_dim):\n",
        "    model = Concatenate()(input_target)\n",
        "    model = BatchNormalization()(model)\n",
        "    model = res_Dense_block(model, name_scope=2)\n",
        "    model = res_Dense_block(model, name_scope=3)\n",
        "    model = BatchNormalization()(model)\n",
        "    model = LeakyReLU()(model)\n",
        "    model = Self_Attention(90, name=\"Self_0\")(model)\n",
        "    model = BatchNormalization()(model)\n",
        "    model = Self_Attention(90, name=\"Self_1\")(model)\n",
        "    model = BatchNormalization()(model)\n",
        "    avg_model = GlobalAveragePooling1D()(model)\n",
        "    max_model = GlobalMaxPooling1D()(model)\n",
        "    model = Concatenate()([avg_model, max_model])\n",
        "    model = BatchNormalization()(model)\n",
        "    model = LeakyReLU()(model)\n",
        "    model = Dense(output_dim, activation='linear', name='final_output')(model)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYneqf9SHSfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#config\n",
        "output_dim = 7\n",
        "emb_max_input = 700\n",
        "input_dim = 90\n",
        "batch_size = 50\n",
        "epochs = 30000\n",
        "input_num = 10\n",
        "data_path = glob.glob(\"./drive/My Drive/Spliter/class_training/*\")\n",
        "label_name = ['high_change_class', 'low_change_class', 'close_change_class', 'close_change_class3']\n",
        "define_loss = Self_define_loss().root_mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bh4xnnfEKkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_target = [Input(shape=(input_dim, 1), name='intput_{}'.format(i)) for i in range(10)]\n",
        "model = layers(input_target)\n",
        "model[0].append(output_layer(model[1], output_dim))\n",
        "save_path = '/drive/My Drive/Model_save/weights'\n",
        "model_train = Model(inputs=input_target, outputs=model[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnfSaCq0FKIL",
        "colab_type": "code",
        "outputId": "b0c681cb-52d3-42c5-ca58-b6ca6a0d8ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "result = fit_model(epochs=epochs, batch_size=batch_size, define_loss=define_loss,\n",
        "                   input_num=input_num, data_path=data_path, label_name=label_name,\n",
        "                   save_path=save_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2083/2083 [==============================] - 9s 4ms/step - loss: 17.8640 - out_0_loss: 1.1684 - out_1_loss: 1.2592 - out_2_loss: 1.2922 - out_3_loss: 1.1954 - out_4_loss: 1.0968 - out_5_loss: 1.0878 - out_6_loss: 1.2050 - out_7_loss: 0.8090 - out_8_loss: 1.3972 - out_9_loss: 1.1499 - final_output_loss: 6.2033 - out_0_acc: 2.6671e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 4.8008e-05 - out_4_acc: 3.7339e-05 - out_5_acc: 3.7339e-05 - out_6_acc: 3.7339e-05 - out_7_acc: 4.8008e-05 - out_8_acc: 1.6003e-05 - out_9_acc: 3.7339e-05 - final_output_acc: 0.1099 - val_loss: 9.9148 - val_out_0_loss: 0.1350 - val_out_1_loss: 0.1236 - val_out_2_loss: 0.2991 - val_out_3_loss: 0.0993 - val_out_4_loss: 0.2914 - val_out_5_loss: 0.2813 - val_out_6_loss: 0.1548 - val_out_7_loss: 0.2036 - val_out_8_loss: 0.0655 - val_out_9_loss: 0.1327 - val_final_output_loss: 8.1285 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 13/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 17.7355 - out_0_loss: 1.1622 - out_1_loss: 1.2423 - out_2_loss: 1.2822 - out_3_loss: 1.1786 - out_4_loss: 1.0837 - out_5_loss: 1.0719 - out_6_loss: 1.1968 - out_7_loss: 0.7917 - out_8_loss: 1.3649 - out_9_loss: 1.1400 - final_output_loss: 6.2213 - out_0_acc: 4.8008e-05 - out_1_acc: 1.6003e-05 - out_2_acc: 1.6003e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 3.2005e-05 - out_5_acc: 4.2673e-05 - out_6_acc: 3.2005e-05 - out_7_acc: 4.8008e-05 - out_8_acc: 3.2005e-05 - out_9_acc: 1.6003e-05 - final_output_acc: 0.1095 - val_loss: 9.8185 - val_out_0_loss: 0.1084 - val_out_1_loss: 0.1114 - val_out_2_loss: 0.2557 - val_out_3_loss: 0.1201 - val_out_4_loss: 0.2699 - val_out_5_loss: 0.2571 - val_out_6_loss: 0.1751 - val_out_7_loss: 0.1914 - val_out_8_loss: 0.0621 - val_out_9_loss: 0.1377 - val_final_output_loss: 8.1296 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 14/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 17.4494 - out_0_loss: 1.1312 - out_1_loss: 1.2017 - out_2_loss: 1.2627 - out_3_loss: 1.1432 - out_4_loss: 1.0588 - out_5_loss: 1.0504 - out_6_loss: 1.1666 - out_7_loss: 0.7900 - out_8_loss: 1.3444 - out_9_loss: 1.1067 - final_output_loss: 6.1938 - out_0_acc: 3.2005e-05 - out_1_acc: 2.1337e-05 - out_2_acc: 2.1337e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 4.8008e-05 - out_5_acc: 3.2005e-05 - out_6_acc: 3.7339e-05 - out_7_acc: 4.8008e-05 - out_8_acc: 2.1337e-05 - out_9_acc: 2.1337e-05 - final_output_acc: 0.1071 - val_loss: 9.1025 - val_out_0_loss: 0.1259 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.2210 - val_out_3_loss: 0.1273 - val_out_4_loss: 0.2833 - val_out_5_loss: 0.2353 - val_out_6_loss: 0.1654 - val_out_7_loss: 0.2211 - val_out_8_loss: 0.0705 - val_out_9_loss: 0.1407 - val_final_output_loss: 7.4032 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 15/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 17.2272 - out_0_loss: 1.1132 - out_1_loss: 1.2032 - out_2_loss: 1.2236 - out_3_loss: 1.1333 - out_4_loss: 1.0489 - out_5_loss: 1.0288 - out_6_loss: 1.1410 - out_7_loss: 0.7665 - out_8_loss: 1.3227 - out_9_loss: 1.0878 - final_output_loss: 6.1582 - out_0_acc: 4.2673e-05 - out_1_acc: 2.6671e-05 - out_2_acc: 3.7339e-05 - out_3_acc: 3.2005e-05 - out_4_acc: 2.6671e-05 - out_5_acc: 4.8008e-05 - out_6_acc: 3.7339e-05 - out_7_acc: 4.8008e-05 - out_8_acc: 3.7339e-05 - out_9_acc: 2.6671e-05 - final_output_acc: 0.1128 - val_loss: 9.1168 - val_out_0_loss: 0.1278 - val_out_1_loss: 0.0928 - val_out_2_loss: 0.2304 - val_out_3_loss: 0.1541 - val_out_4_loss: 0.2697 - val_out_5_loss: 0.2217 - val_out_6_loss: 0.1771 - val_out_7_loss: 0.2202 - val_out_8_loss: 0.0613 - val_out_9_loss: 0.1542 - val_final_output_loss: 7.4074 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 16/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 17.1384 - out_0_loss: 1.0905 - out_1_loss: 1.1707 - out_2_loss: 1.2157 - out_3_loss: 1.1106 - out_4_loss: 1.0238 - out_5_loss: 1.0131 - out_6_loss: 1.1248 - out_7_loss: 0.7515 - out_8_loss: 1.3000 - out_9_loss: 1.0615 - final_output_loss: 6.2762 - out_0_acc: 3.2005e-05 - out_1_acc: 3.2005e-05 - out_2_acc: 4.2673e-05 - out_3_acc: 2.1337e-05 - out_4_acc: 3.2005e-05 - out_5_acc: 2.6671e-05 - out_6_acc: 2.6671e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 3.7339e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1047 - val_loss: 8.9652 - val_out_0_loss: 0.1289 - val_out_1_loss: 0.0895 - val_out_2_loss: 0.1965 - val_out_3_loss: 0.1057 - val_out_4_loss: 0.2585 - val_out_5_loss: 0.2224 - val_out_6_loss: 0.1264 - val_out_7_loss: 0.2238 - val_out_8_loss: 0.0725 - val_out_9_loss: 0.1370 - val_final_output_loss: 7.4038 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 17/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 16.9063 - out_0_loss: 1.0686 - out_1_loss: 1.1435 - out_2_loss: 1.1970 - out_3_loss: 1.1047 - out_4_loss: 1.0187 - out_5_loss: 0.9912 - out_6_loss: 1.0945 - out_7_loss: 0.7472 - out_8_loss: 1.2655 - out_9_loss: 1.0466 - final_output_loss: 6.2289 - out_0_acc: 2.6671e-05 - out_1_acc: 2.6671e-05 - out_2_acc: 2.6671e-05 - out_3_acc: 3.7339e-05 - out_4_acc: 4.8008e-05 - out_5_acc: 4.8008e-05 - out_6_acc: 3.2005e-05 - out_7_acc: 4.8008e-05 - out_8_acc: 3.7339e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1071 - val_loss: 9.6962 - val_out_0_loss: 0.1111 - val_out_1_loss: 0.1039 - val_out_2_loss: 0.2075 - val_out_3_loss: 0.1363 - val_out_4_loss: 0.2321 - val_out_5_loss: 0.1951 - val_out_6_loss: 0.1708 - val_out_7_loss: 0.2106 - val_out_8_loss: 0.0496 - val_out_9_loss: 0.1378 - val_final_output_loss: 8.1414 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 18/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 16.4270 - out_0_loss: 1.0560 - out_1_loss: 1.1270 - out_2_loss: 1.1570 - out_3_loss: 1.0889 - out_4_loss: 0.9827 - out_5_loss: 0.9881 - out_6_loss: 1.0735 - out_7_loss: 0.7304 - out_8_loss: 1.2514 - out_9_loss: 1.0289 - final_output_loss: 5.9429 - out_0_acc: 3.7339e-05 - out_1_acc: 2.6671e-05 - out_2_acc: 4.2673e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 4.2673e-05 - out_5_acc: 3.2005e-05 - out_6_acc: 4.8008e-05 - out_7_acc: 5.3342e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 3.7339e-05 - final_output_acc: 0.1066 - val_loss: 8.1787 - val_out_0_loss: 0.1091 - val_out_1_loss: 0.0811 - val_out_2_loss: 0.1727 - val_out_3_loss: 0.1341 - val_out_4_loss: 0.2537 - val_out_5_loss: 0.2118 - val_out_6_loss: 0.1246 - val_out_7_loss: 0.2148 - val_out_8_loss: 0.0600 - val_out_9_loss: 0.1406 - val_final_output_loss: 6.6761 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 19/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 16.3358 - out_0_loss: 1.0352 - out_1_loss: 1.1043 - out_2_loss: 1.1480 - out_3_loss: 1.0574 - out_4_loss: 0.9753 - out_5_loss: 0.9576 - out_6_loss: 1.0690 - out_7_loss: 0.7165 - out_8_loss: 1.2194 - out_9_loss: 1.0106 - final_output_loss: 6.0425 - out_0_acc: 3.2005e-05 - out_1_acc: 2.6671e-05 - out_2_acc: 4.2673e-05 - out_3_acc: 3.2005e-05 - out_4_acc: 2.6671e-05 - out_5_acc: 2.6671e-05 - out_6_acc: 2.1337e-05 - out_7_acc: 5.3342e-05 - out_8_acc: 3.7339e-05 - out_9_acc: 3.7339e-05 - final_output_acc: 0.1152 - val_loss: 8.1262 - val_out_0_loss: 0.1085 - val_out_1_loss: 0.0731 - val_out_2_loss: 0.1568 - val_out_3_loss: 0.1394 - val_out_4_loss: 0.2146 - val_out_5_loss: 0.1884 - val_out_6_loss: 0.1439 - val_out_7_loss: 0.2207 - val_out_8_loss: 0.0569 - val_out_9_loss: 0.1347 - val_final_output_loss: 6.6892 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 20/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 16.3627 - out_0_loss: 1.0204 - out_1_loss: 1.0775 - out_2_loss: 1.1291 - out_3_loss: 1.0538 - out_4_loss: 0.9604 - out_5_loss: 0.9583 - out_6_loss: 1.0616 - out_7_loss: 0.7144 - out_8_loss: 1.2099 - out_9_loss: 0.9985 - final_output_loss: 6.1789 - out_0_acc: 4.8008e-05 - out_1_acc: 2.6671e-05 - out_2_acc: 3.7339e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 4.8008e-05 - out_5_acc: 3.2005e-05 - out_6_acc: 4.2673e-05 - out_7_acc: 4.2673e-05 - out_8_acc: 2.6671e-05 - out_9_acc: 4.2673e-05 - final_output_acc: 0.1167 - val_loss: 9.0891 - val_out_0_loss: 0.1346 - val_out_1_loss: 0.0732 - val_out_2_loss: 0.1359 - val_out_3_loss: 0.1376 - val_out_4_loss: 0.2248 - val_out_5_loss: 0.1688 - val_out_6_loss: 0.1389 - val_out_7_loss: 0.2319 - val_out_8_loss: 0.0615 - val_out_9_loss: 0.1334 - val_final_output_loss: 7.6485 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 21/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 16.2782 - out_0_loss: 1.0068 - out_1_loss: 1.0738 - out_2_loss: 1.1043 - out_3_loss: 1.0464 - out_4_loss: 0.9435 - out_5_loss: 0.9378 - out_6_loss: 1.0336 - out_7_loss: 0.6941 - out_8_loss: 1.1798 - out_9_loss: 0.9640 - final_output_loss: 6.2941 - out_0_acc: 3.7339e-05 - out_1_acc: 3.7339e-05 - out_2_acc: 4.8008e-05 - out_3_acc: 3.7339e-05 - out_4_acc: 4.8008e-05 - out_5_acc: 5.3342e-05 - out_6_acc: 2.6671e-05 - out_7_acc: 4.8008e-05 - out_8_acc: 2.1337e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1195 - val_loss: 9.1469 - val_out_0_loss: 0.1286 - val_out_1_loss: 0.0807 - val_out_2_loss: 0.1419 - val_out_3_loss: 0.1490 - val_out_4_loss: 0.2164 - val_out_5_loss: 0.1736 - val_out_6_loss: 0.1106 - val_out_7_loss: 0.2292 - val_out_8_loss: 0.0892 - val_out_9_loss: 0.1685 - val_final_output_loss: 7.6592 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 22/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 16.2182 - out_0_loss: 0.9802 - out_1_loss: 1.0563 - out_2_loss: 1.0879 - out_3_loss: 1.0061 - out_4_loss: 0.9296 - out_5_loss: 0.9297 - out_6_loss: 1.0200 - out_7_loss: 0.6822 - out_8_loss: 1.1695 - out_9_loss: 0.9573 - final_output_loss: 6.3993 - out_0_acc: 3.2005e-05 - out_1_acc: 3.7339e-05 - out_2_acc: 3.7339e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 5.3342e-05 - out_6_acc: 4.8008e-05 - out_7_acc: 5.3342e-05 - out_8_acc: 3.2005e-05 - out_9_acc: 3.2005e-05 - final_output_acc: 0.1200 - val_loss: 8.9578 - val_out_0_loss: 0.0946 - val_out_1_loss: 0.0734 - val_out_2_loss: 0.1193 - val_out_3_loss: 0.1056 - val_out_4_loss: 0.1998 - val_out_5_loss: 0.1573 - val_out_6_loss: 0.1087 - val_out_7_loss: 0.2006 - val_out_8_loss: 0.0808 - val_out_9_loss: 0.1331 - val_final_output_loss: 7.6845 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 23/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 15.8753 - out_0_loss: 0.9647 - out_1_loss: 1.0341 - out_2_loss: 1.0836 - out_3_loss: 1.0084 - out_4_loss: 0.9153 - out_5_loss: 0.9183 - out_6_loss: 0.9930 - out_7_loss: 0.6774 - out_8_loss: 1.1501 - out_9_loss: 0.9578 - final_output_loss: 6.1726 - out_0_acc: 4.2673e-05 - out_1_acc: 3.2005e-05 - out_2_acc: 2.1337e-05 - out_3_acc: 3.2005e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 4.2673e-05 - out_6_acc: 1.6003e-05 - out_7_acc: 5.3342e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 3.7339e-05 - final_output_acc: 0.1162 - val_loss: 8.3197 - val_out_0_loss: 0.1145 - val_out_1_loss: 0.0642 - val_out_2_loss: 0.1148 - val_out_3_loss: 0.1252 - val_out_4_loss: 0.2305 - val_out_5_loss: 0.1705 - val_out_6_loss: 0.0838 - val_out_7_loss: 0.2218 - val_out_8_loss: 0.0996 - val_out_9_loss: 0.1350 - val_final_output_loss: 6.9598 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 24/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 15.7621 - out_0_loss: 0.9566 - out_1_loss: 1.0126 - out_2_loss: 1.0578 - out_3_loss: 0.9917 - out_4_loss: 0.8948 - out_5_loss: 0.8997 - out_6_loss: 0.9875 - out_7_loss: 0.6689 - out_8_loss: 1.1352 - out_9_loss: 0.9287 - final_output_loss: 6.2286 - out_0_acc: 4.2673e-05 - out_1_acc: 3.2005e-05 - out_2_acc: 3.7339e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 3.2005e-05 - out_5_acc: 4.8008e-05 - out_6_acc: 3.7339e-05 - out_7_acc: 4.8008e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 2.6671e-05 - final_output_acc: 0.1114 - val_loss: 9.0320 - val_out_0_loss: 0.1014 - val_out_1_loss: 0.0632 - val_out_2_loss: 0.1084 - val_out_3_loss: 0.1496 - val_out_4_loss: 0.2113 - val_out_5_loss: 0.1637 - val_out_6_loss: 0.0828 - val_out_7_loss: 0.2126 - val_out_8_loss: 0.0936 - val_out_9_loss: 0.1364 - val_final_output_loss: 7.7091 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 25/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 15.9747 - out_0_loss: 0.9377 - out_1_loss: 1.0022 - out_2_loss: 1.0431 - out_3_loss: 0.9663 - out_4_loss: 0.8948 - out_5_loss: 0.8865 - out_6_loss: 0.9663 - out_7_loss: 0.6565 - out_8_loss: 1.1213 - out_9_loss: 0.9094 - final_output_loss: 6.5907 - out_0_acc: 3.2005e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 3.2005e-05 - out_3_acc: 4.8008e-05 - out_4_acc: 2.6671e-05 - out_5_acc: 3.7339e-05 - out_6_acc: 4.2673e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 3.2005e-05 - out_9_acc: 3.7339e-05 - final_output_acc: 0.1152 - val_loss: 9.7234 - val_out_0_loss: 0.1074 - val_out_1_loss: 0.0660 - val_out_2_loss: 0.1069 - val_out_3_loss: 0.1497 - val_out_4_loss: 0.1936 - val_out_5_loss: 0.1498 - val_out_6_loss: 0.1138 - val_out_7_loss: 0.2125 - val_out_8_loss: 0.0873 - val_out_9_loss: 0.1588 - val_final_output_loss: 8.3775 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 26/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 15.4788 - out_0_loss: 0.9241 - out_1_loss: 0.9962 - out_2_loss: 1.0189 - out_3_loss: 0.9623 - out_4_loss: 0.8731 - out_5_loss: 0.8679 - out_6_loss: 0.9449 - out_7_loss: 0.6427 - out_8_loss: 1.1110 - out_9_loss: 0.8910 - final_output_loss: 6.2467 - out_0_acc: 4.2673e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 3.7339e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 3.7339e-05 - out_5_acc: 4.8008e-05 - out_6_acc: 4.2673e-05 - out_7_acc: 3.7339e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 4.8008e-05 - final_output_acc: 0.1200 - val_loss: 9.0271 - val_out_0_loss: 0.0731 - val_out_1_loss: 0.0741 - val_out_2_loss: 0.1036 - val_out_3_loss: 0.1333 - val_out_4_loss: 0.1930 - val_out_5_loss: 0.1399 - val_out_6_loss: 0.0739 - val_out_7_loss: 0.2127 - val_out_8_loss: 0.1102 - val_out_9_loss: 0.1501 - val_final_output_loss: 7.7633 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 27/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 15.1669 - out_0_loss: 0.9087 - out_1_loss: 0.9681 - out_2_loss: 1.0007 - out_3_loss: 0.9468 - out_4_loss: 0.8582 - out_5_loss: 0.8683 - out_6_loss: 0.9441 - out_7_loss: 0.6357 - out_8_loss: 1.0883 - out_9_loss: 0.8844 - final_output_loss: 6.0638 - out_0_acc: 3.2005e-05 - out_1_acc: 4.2673e-05 - out_2_acc: 3.2005e-05 - out_3_acc: 3.2005e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 3.7339e-05 - out_6_acc: 4.2673e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 3.7339e-05 - out_9_acc: 2.1337e-05 - final_output_acc: 0.1085 - val_loss: 8.9914 - val_out_0_loss: 0.0975 - val_out_1_loss: 0.0648 - val_out_2_loss: 0.0894 - val_out_3_loss: 0.1392 - val_out_4_loss: 0.2116 - val_out_5_loss: 0.1189 - val_out_6_loss: 0.0614 - val_out_7_loss: 0.2076 - val_out_8_loss: 0.1025 - val_out_9_loss: 0.1269 - val_final_output_loss: 7.7717 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 28/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 15.2796 - out_0_loss: 0.8904 - out_1_loss: 0.9476 - out_2_loss: 0.9955 - out_3_loss: 0.9370 - out_4_loss: 0.8463 - out_5_loss: 0.8448 - out_6_loss: 0.9278 - out_7_loss: 0.6269 - out_8_loss: 1.0691 - out_9_loss: 0.8703 - final_output_loss: 6.3239 - out_0_acc: 5.3342e-05 - out_1_acc: 3.2005e-05 - out_2_acc: 3.2005e-05 - out_3_acc: 3.7339e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 4.2673e-05 - out_6_acc: 3.2005e-05 - out_7_acc: 4.2673e-05 - out_8_acc: 3.7339e-05 - out_9_acc: 3.2005e-05 - final_output_acc: 0.1147 - val_loss: 8.9496 - val_out_0_loss: 0.1033 - val_out_1_loss: 0.0580 - val_out_2_loss: 0.0873 - val_out_3_loss: 0.1505 - val_out_4_loss: 0.1818 - val_out_5_loss: 0.1474 - val_out_6_loss: 0.0564 - val_out_7_loss: 0.1966 - val_out_8_loss: 0.0834 - val_out_9_loss: 0.1131 - val_final_output_loss: 7.7718 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 29/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 15.2096 - out_0_loss: 0.8911 - out_1_loss: 0.9414 - out_2_loss: 0.9666 - out_3_loss: 0.9282 - out_4_loss: 0.8360 - out_5_loss: 0.8258 - out_6_loss: 0.9175 - out_7_loss: 0.6174 - out_8_loss: 1.0584 - out_9_loss: 0.8539 - final_output_loss: 6.3733 - out_0_acc: 4.2673e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 3.2005e-05 - out_5_acc: 5.3342e-05 - out_6_acc: 3.7339e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 2.6671e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1128 - val_loss: 9.1142 - val_out_0_loss: 0.0681 - val_out_1_loss: 0.0511 - val_out_2_loss: 0.0922 - val_out_3_loss: 0.1465 - val_out_4_loss: 0.2121 - val_out_5_loss: 0.1459 - val_out_6_loss: 0.0728 - val_out_7_loss: 0.1909 - val_out_8_loss: 0.0922 - val_out_9_loss: 0.1310 - val_final_output_loss: 7.9114 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 30/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 15.0897 - out_0_loss: 0.8746 - out_1_loss: 0.9243 - out_2_loss: 0.9523 - out_3_loss: 0.9071 - out_4_loss: 0.8231 - out_5_loss: 0.8174 - out_6_loss: 0.8940 - out_7_loss: 0.6085 - out_8_loss: 1.0450 - out_9_loss: 0.8422 - final_output_loss: 6.4012 - out_0_acc: 5.3342e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 4.8008e-05 - out_3_acc: 3.7339e-05 - out_4_acc: 4.8008e-05 - out_5_acc: 5.3342e-05 - out_6_acc: 4.2673e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 3.7339e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1032 - val_loss: 9.5548 - val_out_0_loss: 0.0968 - val_out_1_loss: 0.0533 - val_out_2_loss: 0.0783 - val_out_3_loss: 0.1565 - val_out_4_loss: 0.1679 - val_out_5_loss: 0.1178 - val_out_6_loss: 0.0620 - val_out_7_loss: 0.1880 - val_out_8_loss: 0.1146 - val_out_9_loss: 0.1316 - val_final_output_loss: 8.3877 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 31/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 14.8068 - out_0_loss: 0.8630 - out_1_loss: 0.9080 - out_2_loss: 0.9416 - out_3_loss: 0.8984 - out_4_loss: 0.8186 - out_5_loss: 0.8077 - out_6_loss: 0.8821 - out_7_loss: 0.6037 - out_8_loss: 1.0374 - out_9_loss: 0.8280 - final_output_loss: 6.2183 - out_0_acc: 4.8008e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 5.3342e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 5.3342e-05 - out_6_acc: 3.2005e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 4.2673e-05 - final_output_acc: 0.1018 - val_loss: 8.9578 - val_out_0_loss: 0.1016 - val_out_1_loss: 0.0653 - val_out_2_loss: 0.0760 - val_out_3_loss: 0.1353 - val_out_4_loss: 0.2140 - val_out_5_loss: 0.1460 - val_out_6_loss: 0.0501 - val_out_7_loss: 0.1908 - val_out_8_loss: 0.1124 - val_out_9_loss: 0.1516 - val_final_output_loss: 7.7146 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 32/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 14.5181 - out_0_loss: 0.8356 - out_1_loss: 0.8948 - out_2_loss: 0.9288 - out_3_loss: 0.8816 - out_4_loss: 0.7960 - out_5_loss: 0.8007 - out_6_loss: 0.8787 - out_7_loss: 0.5945 - out_8_loss: 1.0145 - out_9_loss: 0.8146 - final_output_loss: 6.0783 - out_0_acc: 5.3342e-05 - out_1_acc: 4.2673e-05 - out_2_acc: 5.3342e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 4.2673e-05 - out_8_acc: 3.2005e-05 - out_9_acc: 3.2005e-05 - final_output_acc: 0.1147 - val_loss: 8.9244 - val_out_0_loss: 0.0825 - val_out_1_loss: 0.0498 - val_out_2_loss: 0.0792 - val_out_3_loss: 0.1659 - val_out_4_loss: 0.2036 - val_out_5_loss: 0.1158 - val_out_6_loss: 0.0462 - val_out_7_loss: 0.2217 - val_out_8_loss: 0.1231 - val_out_9_loss: 0.1356 - val_final_output_loss: 7.7010 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 33/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 14.6487 - out_0_loss: 0.8341 - out_1_loss: 0.8813 - out_2_loss: 0.9240 - out_3_loss: 0.8757 - out_4_loss: 0.7866 - out_5_loss: 0.7856 - out_6_loss: 0.8584 - out_7_loss: 0.5845 - out_8_loss: 1.0061 - out_9_loss: 0.8038 - final_output_loss: 6.3085 - out_0_acc: 3.2005e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 4.8008e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 4.2673e-05 - out_5_acc: 3.2005e-05 - out_6_acc: 4.2673e-05 - out_7_acc: 5.3342e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1138 - val_loss: 8.9204 - val_out_0_loss: 0.0897 - val_out_1_loss: 0.0739 - val_out_2_loss: 0.0798 - val_out_3_loss: 0.1454 - val_out_4_loss: 0.2063 - val_out_5_loss: 0.1211 - val_out_6_loss: 0.0456 - val_out_7_loss: 0.1948 - val_out_8_loss: 0.0840 - val_out_9_loss: 0.1495 - val_final_output_loss: 7.7302 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 34/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 14.5299 - out_0_loss: 0.8217 - out_1_loss: 0.8636 - out_2_loss: 0.9028 - out_3_loss: 0.8635 - out_4_loss: 0.7826 - out_5_loss: 0.7769 - out_6_loss: 0.8368 - out_7_loss: 0.5841 - out_8_loss: 1.0069 - out_9_loss: 0.7785 - final_output_loss: 6.3125 - out_0_acc: 4.2673e-05 - out_1_acc: 4.2673e-05 - out_2_acc: 4.2673e-05 - out_3_acc: 4.8008e-05 - out_4_acc: 4.2673e-05 - out_5_acc: 4.8008e-05 - out_6_acc: 4.8008e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 3.2005e-05 - out_9_acc: 3.7339e-05 - final_output_acc: 0.1138 - val_loss: 8.9309 - val_out_0_loss: 0.1054 - val_out_1_loss: 0.0669 - val_out_2_loss: 0.0845 - val_out_3_loss: 0.1474 - val_out_4_loss: 0.1890 - val_out_5_loss: 0.1128 - val_out_6_loss: 0.0472 - val_out_7_loss: 0.1812 - val_out_8_loss: 0.1167 - val_out_9_loss: 0.1492 - val_final_output_loss: 7.7307 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 35/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 14.3313 - out_0_loss: 0.8134 - out_1_loss: 0.8527 - out_2_loss: 0.9064 - out_3_loss: 0.8505 - out_4_loss: 0.7682 - out_5_loss: 0.7606 - out_6_loss: 0.8284 - out_7_loss: 0.5694 - out_8_loss: 0.9746 - out_9_loss: 0.7797 - final_output_loss: 6.2274 - out_0_acc: 4.2673e-05 - out_1_acc: 2.6671e-05 - out_2_acc: 3.7339e-05 - out_3_acc: 3.7339e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 3.2005e-05 - out_6_acc: 4.8008e-05 - out_7_acc: 5.3342e-05 - out_8_acc: 3.2005e-05 - out_9_acc: 4.2673e-05 - final_output_acc: 0.1085 - val_loss: 8.9043 - val_out_0_loss: 0.0942 - val_out_1_loss: 0.0751 - val_out_2_loss: 0.0897 - val_out_3_loss: 0.1380 - val_out_4_loss: 0.1753 - val_out_5_loss: 0.1170 - val_out_6_loss: 0.0463 - val_out_7_loss: 0.1894 - val_out_8_loss: 0.1056 - val_out_9_loss: 0.1397 - val_final_output_loss: 7.7341 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 36/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 14.0007 - out_0_loss: 0.7961 - out_1_loss: 0.8480 - out_2_loss: 0.8693 - out_3_loss: 0.8460 - out_4_loss: 0.7539 - out_5_loss: 0.7494 - out_6_loss: 0.8229 - out_7_loss: 0.5635 - out_8_loss: 0.9601 - out_9_loss: 0.7706 - final_output_loss: 6.0208 - out_0_acc: 4.2673e-05 - out_1_acc: 5.8676e-05 - out_2_acc: 4.8008e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 5.3342e-05 - out_6_acc: 3.7339e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 4.2673e-05 - final_output_acc: 0.1133 - val_loss: 9.0005 - val_out_0_loss: 0.1032 - val_out_1_loss: 0.0548 - val_out_2_loss: 0.0874 - val_out_3_loss: 0.1692 - val_out_4_loss: 0.2084 - val_out_5_loss: 0.1338 - val_out_6_loss: 0.0429 - val_out_7_loss: 0.2004 - val_out_8_loss: 0.1263 - val_out_9_loss: 0.1553 - val_final_output_loss: 7.7188 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 37/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 13.7778 - out_0_loss: 0.7893 - out_1_loss: 0.8277 - out_2_loss: 0.8562 - out_3_loss: 0.8224 - out_4_loss: 0.7406 - out_5_loss: 0.7470 - out_6_loss: 0.7990 - out_7_loss: 0.5519 - out_8_loss: 0.9555 - out_9_loss: 0.7488 - final_output_loss: 5.9395 - out_0_acc: 5.3342e-05 - out_1_acc: 4.2673e-05 - out_2_acc: 5.3342e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 4.2673e-05 - out_5_acc: 4.2673e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 5.3342e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1176 - val_loss: 8.8873 - val_out_0_loss: 0.0960 - val_out_1_loss: 0.0692 - val_out_2_loss: 0.0751 - val_out_3_loss: 0.1543 - val_out_4_loss: 0.1843 - val_out_5_loss: 0.1048 - val_out_6_loss: 0.0389 - val_out_7_loss: 0.1856 - val_out_8_loss: 0.1075 - val_out_9_loss: 0.1424 - val_final_output_loss: 7.7293 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 38/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 13.9355 - out_0_loss: 0.7719 - out_1_loss: 0.8321 - out_2_loss: 0.8465 - out_3_loss: 0.8150 - out_4_loss: 0.7325 - out_5_loss: 0.7319 - out_6_loss: 0.7867 - out_7_loss: 0.5465 - out_8_loss: 0.9325 - out_9_loss: 0.7345 - final_output_loss: 6.2055 - out_0_acc: 5.3342e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 4.8008e-05 - out_3_acc: 3.7339e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 3.7339e-05 - out_6_acc: 4.2673e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 4.2673e-05 - out_9_acc: 4.2673e-05 - final_output_acc: 0.1335 - val_loss: 9.6452 - val_out_0_loss: 0.1040 - val_out_1_loss: 0.0772 - val_out_2_loss: 0.1166 - val_out_3_loss: 0.1599 - val_out_4_loss: 0.1876 - val_out_5_loss: 0.1128 - val_out_6_loss: 0.0341 - val_out_7_loss: 0.2074 - val_out_8_loss: 0.1176 - val_out_9_loss: 0.1225 - val_final_output_loss: 8.4054 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 39/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 13.7751 - out_0_loss: 0.7626 - out_1_loss: 0.7995 - out_2_loss: 0.8306 - out_3_loss: 0.8122 - out_4_loss: 0.7157 - out_5_loss: 0.7301 - out_6_loss: 0.7716 - out_7_loss: 0.5431 - out_8_loss: 0.9306 - out_9_loss: 0.7318 - final_output_loss: 6.1472 - out_0_acc: 4.8008e-05 - out_1_acc: 4.2673e-05 - out_2_acc: 5.3342e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 4.2673e-05 - out_6_acc: 4.8008e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 4.2673e-05 - final_output_acc: 0.1229 - val_loss: 8.9682 - val_out_0_loss: 0.0865 - val_out_1_loss: 0.0860 - val_out_2_loss: 0.0882 - val_out_3_loss: 0.1601 - val_out_4_loss: 0.1636 - val_out_5_loss: 0.0882 - val_out_6_loss: 0.0334 - val_out_7_loss: 0.1946 - val_out_8_loss: 0.1143 - val_out_9_loss: 0.1222 - val_final_output_loss: 7.8312 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 40/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 13.7857 - out_0_loss: 0.7532 - out_1_loss: 0.7958 - out_2_loss: 0.8271 - out_3_loss: 0.8017 - out_4_loss: 0.7109 - out_5_loss: 0.7149 - out_6_loss: 0.7669 - out_7_loss: 0.5363 - out_8_loss: 0.9130 - out_9_loss: 0.7141 - final_output_loss: 6.2519 - out_0_acc: 5.3342e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 4.8008e-05 - out_3_acc: 3.7339e-05 - out_4_acc: 4.2673e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 4.8008e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 4.2673e-05 - final_output_acc: 0.1229 - val_loss: 9.5222 - val_out_0_loss: 0.0935 - val_out_1_loss: 0.0504 - val_out_2_loss: 0.0841 - val_out_3_loss: 0.1222 - val_out_4_loss: 0.1839 - val_out_5_loss: 0.0990 - val_out_6_loss: 0.0305 - val_out_7_loss: 0.1836 - val_out_8_loss: 0.1048 - val_out_9_loss: 0.1411 - val_final_output_loss: 8.4290 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 41/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 13.5921 - out_0_loss: 0.7454 - out_1_loss: 0.7868 - out_2_loss: 0.8202 - out_3_loss: 0.7895 - out_4_loss: 0.7003 - out_5_loss: 0.7044 - out_6_loss: 0.7526 - out_7_loss: 0.5235 - out_8_loss: 0.8996 - out_9_loss: 0.7069 - final_output_loss: 6.1629 - out_0_acc: 4.8008e-05 - out_1_acc: 4.2673e-05 - out_2_acc: 5.3342e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 3.7339e-05 - out_5_acc: 4.2673e-05 - out_6_acc: 4.2673e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 3.7339e-05 - final_output_acc: 0.1181 - val_loss: 9.6067 - val_out_0_loss: 0.0922 - val_out_1_loss: 0.0724 - val_out_2_loss: 0.1044 - val_out_3_loss: 0.1573 - val_out_4_loss: 0.1570 - val_out_5_loss: 0.1064 - val_out_6_loss: 0.0504 - val_out_7_loss: 0.1878 - val_out_8_loss: 0.1228 - val_out_9_loss: 0.1470 - val_final_output_loss: 8.4090 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0455\n",
            "Epoch 42/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 13.3713 - out_0_loss: 0.7373 - out_1_loss: 0.7626 - out_2_loss: 0.8062 - out_3_loss: 0.7682 - out_4_loss: 0.6862 - out_5_loss: 0.7000 - out_6_loss: 0.7548 - out_7_loss: 0.5223 - out_8_loss: 0.8917 - out_9_loss: 0.6916 - final_output_loss: 6.0503 - out_0_acc: 5.8676e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 5.3342e-05 - out_3_acc: 3.2005e-05 - out_4_acc: 4.2673e-05 - out_5_acc: 3.7339e-05 - out_6_acc: 4.8008e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 3.2005e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1157 - val_loss: 8.8597 - val_out_0_loss: 0.0955 - val_out_1_loss: 0.0693 - val_out_2_loss: 0.1113 - val_out_3_loss: 0.1485 - val_out_4_loss: 0.1612 - val_out_5_loss: 0.0900 - val_out_6_loss: 0.0358 - val_out_7_loss: 0.1824 - val_out_8_loss: 0.0808 - val_out_9_loss: 0.1270 - val_final_output_loss: 7.7580 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 43/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 13.4533 - out_0_loss: 0.7299 - out_1_loss: 0.7494 - out_2_loss: 0.7895 - out_3_loss: 0.7736 - out_4_loss: 0.6865 - out_5_loss: 0.6870 - out_6_loss: 0.7206 - out_7_loss: 0.5155 - out_8_loss: 0.8697 - out_9_loss: 0.6857 - final_output_loss: 6.2459 - out_0_acc: 4.2673e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 4.2673e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 4.8008e-05 - out_5_acc: 3.7339e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 2.1337e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1128 - val_loss: 8.8384 - val_out_0_loss: 0.0949 - val_out_1_loss: 0.0447 - val_out_2_loss: 0.0836 - val_out_3_loss: 0.1234 - val_out_4_loss: 0.1679 - val_out_5_loss: 0.0869 - val_out_6_loss: 0.0250 - val_out_7_loss: 0.1697 - val_out_8_loss: 0.1105 - val_out_9_loss: 0.1405 - val_final_output_loss: 7.7912 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 44/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 13.2876 - out_0_loss: 0.7190 - out_1_loss: 0.7472 - out_2_loss: 0.7747 - out_3_loss: 0.7635 - out_4_loss: 0.6825 - out_5_loss: 0.6757 - out_6_loss: 0.7211 - out_7_loss: 0.5090 - out_8_loss: 0.8675 - out_9_loss: 0.6717 - final_output_loss: 6.1557 - out_0_acc: 5.8676e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 4.2673e-05 - out_3_acc: 3.7339e-05 - out_4_acc: 3.7339e-05 - out_5_acc: 3.7339e-05 - out_6_acc: 4.2673e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 4.2673e-05 - out_9_acc: 4.8008e-05 - final_output_acc: 0.1243 - val_loss: 9.6302 - val_out_0_loss: 0.0895 - val_out_1_loss: 0.0712 - val_out_2_loss: 0.1081 - val_out_3_loss: 0.1386 - val_out_4_loss: 0.1386 - val_out_5_loss: 0.0821 - val_out_6_loss: 0.0415 - val_out_7_loss: 0.1781 - val_out_8_loss: 0.1007 - val_out_9_loss: 0.1522 - val_final_output_loss: 8.5296 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0909\n",
            "Epoch 45/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 13.2142 - out_0_loss: 0.7082 - out_1_loss: 0.7439 - out_2_loss: 0.7639 - out_3_loss: 0.7627 - out_4_loss: 0.6636 - out_5_loss: 0.6665 - out_6_loss: 0.7026 - out_7_loss: 0.5019 - out_8_loss: 0.8551 - out_9_loss: 0.6586 - final_output_loss: 6.1871 - out_0_acc: 4.8008e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 3.7339e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 4.8008e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 3.7339e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1167 - val_loss: 8.9726 - val_out_0_loss: 0.0930 - val_out_1_loss: 0.0722 - val_out_2_loss: 0.0935 - val_out_3_loss: 0.1458 - val_out_4_loss: 0.1521 - val_out_5_loss: 0.0928 - val_out_6_loss: 0.0558 - val_out_7_loss: 0.2069 - val_out_8_loss: 0.1115 - val_out_9_loss: 0.1812 - val_final_output_loss: 7.7680 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 46/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 13.0773 - out_0_loss: 0.6987 - out_1_loss: 0.7328 - out_2_loss: 0.7541 - out_3_loss: 0.7416 - out_4_loss: 0.6577 - out_5_loss: 0.6630 - out_6_loss: 0.6953 - out_7_loss: 0.4959 - out_8_loss: 0.8353 - out_9_loss: 0.6542 - final_output_loss: 6.1486 - out_0_acc: 5.3342e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 3.7339e-05 - out_3_acc: 3.7339e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 3.2005e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 4.8008e-05 - final_output_acc: 0.1104 - val_loss: 8.9358 - val_out_0_loss: 0.1018 - val_out_1_loss: 0.0638 - val_out_2_loss: 0.1102 - val_out_3_loss: 0.1460 - val_out_4_loss: 0.1556 - val_out_5_loss: 0.0777 - val_out_6_loss: 0.0407 - val_out_7_loss: 0.1991 - val_out_8_loss: 0.1084 - val_out_9_loss: 0.1608 - val_final_output_loss: 7.7716 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 47/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.7483 - out_0_loss: 0.6869 - out_1_loss: 0.7226 - out_2_loss: 0.7457 - out_3_loss: 0.7275 - out_4_loss: 0.6437 - out_5_loss: 0.6449 - out_6_loss: 0.6831 - out_7_loss: 0.4865 - out_8_loss: 0.8230 - out_9_loss: 0.6392 - final_output_loss: 5.9453 - out_0_acc: 4.8008e-05 - out_1_acc: 5.8676e-05 - out_2_acc: 3.7339e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 5.3342e-05 - out_6_acc: 3.7339e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1152 - val_loss: 8.8783 - val_out_0_loss: 0.0839 - val_out_1_loss: 0.0610 - val_out_2_loss: 0.0911 - val_out_3_loss: 0.1456 - val_out_4_loss: 0.1558 - val_out_5_loss: 0.0855 - val_out_6_loss: 0.0422 - val_out_7_loss: 0.1953 - val_out_8_loss: 0.1080 - val_out_9_loss: 0.1540 - val_final_output_loss: 7.7560 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 48/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.8610 - out_0_loss: 0.6773 - out_1_loss: 0.7089 - out_2_loss: 0.7420 - out_3_loss: 0.7177 - out_4_loss: 0.6362 - out_5_loss: 0.6460 - out_6_loss: 0.6725 - out_7_loss: 0.4797 - out_8_loss: 0.8249 - out_9_loss: 0.6339 - final_output_loss: 6.1220 - out_0_acc: 4.8008e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 4.8008e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 4.8008e-05 - out_6_acc: 4.2673e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 3.7339e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1215 - val_loss: 9.7051 - val_out_0_loss: 0.0981 - val_out_1_loss: 0.0699 - val_out_2_loss: 0.0948 - val_out_3_loss: 0.1431 - val_out_4_loss: 0.1743 - val_out_5_loss: 0.0914 - val_out_6_loss: 0.0481 - val_out_7_loss: 0.2084 - val_out_8_loss: 0.1147 - val_out_9_loss: 0.1399 - val_final_output_loss: 8.5224 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0909\n",
            "Epoch 49/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.8677 - out_0_loss: 0.6663 - out_1_loss: 0.6988 - out_2_loss: 0.7319 - out_3_loss: 0.7167 - out_4_loss: 0.6287 - out_5_loss: 0.6298 - out_6_loss: 0.6693 - out_7_loss: 0.4735 - out_8_loss: 0.8118 - out_9_loss: 0.6269 - final_output_loss: 6.2139 - out_0_acc: 5.8676e-05 - out_1_acc: 5.8676e-05 - out_2_acc: 4.8008e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 4.8008e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1119 - val_loss: 8.5403 - val_out_0_loss: 0.0868 - val_out_1_loss: 0.0485 - val_out_2_loss: 0.1091 - val_out_3_loss: 0.1611 - val_out_4_loss: 0.1460 - val_out_5_loss: 0.0852 - val_out_6_loss: 0.0522 - val_out_7_loss: 0.1842 - val_out_8_loss: 0.1082 - val_out_9_loss: 0.1609 - val_final_output_loss: 7.3980 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 50/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.7063 - out_0_loss: 0.6583 - out_1_loss: 0.6915 - out_2_loss: 0.7099 - out_3_loss: 0.7077 - out_4_loss: 0.6236 - out_5_loss: 0.6297 - out_6_loss: 0.6419 - out_7_loss: 0.4689 - out_8_loss: 0.8061 - out_9_loss: 0.6133 - final_output_loss: 6.1553 - out_0_acc: 5.8676e-05 - out_1_acc: 3.7339e-05 - out_2_acc: 4.2673e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 3.2005e-05 - out_5_acc: 3.7339e-05 - out_6_acc: 5.8676e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1195 - val_loss: 9.3778 - val_out_0_loss: 0.0928 - val_out_1_loss: 0.0627 - val_out_2_loss: 0.1249 - val_out_3_loss: 0.1582 - val_out_4_loss: 0.1985 - val_out_5_loss: 0.0926 - val_out_6_loss: 0.0704 - val_out_7_loss: 0.1829 - val_out_8_loss: 0.1134 - val_out_9_loss: 0.1301 - val_final_output_loss: 8.1514 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 51/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.8120 - out_0_loss: 0.6482 - out_1_loss: 0.6752 - out_2_loss: 0.6972 - out_3_loss: 0.6996 - out_4_loss: 0.6091 - out_5_loss: 0.6171 - out_6_loss: 0.6438 - out_7_loss: 0.4639 - out_8_loss: 0.7914 - out_9_loss: 0.6032 - final_output_loss: 6.3634 - out_0_acc: 5.3342e-05 - out_1_acc: 4.2673e-05 - out_2_acc: 4.2673e-05 - out_3_acc: 3.7339e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 4.2673e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 3.2005e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1234 - val_loss: 8.9227 - val_out_0_loss: 0.0869 - val_out_1_loss: 0.0597 - val_out_2_loss: 0.1143 - val_out_3_loss: 0.1595 - val_out_4_loss: 0.1670 - val_out_5_loss: 0.0851 - val_out_6_loss: 0.0588 - val_out_7_loss: 0.1993 - val_out_8_loss: 0.1001 - val_out_9_loss: 0.1260 - val_final_output_loss: 7.7660 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 52/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.5950 - out_0_loss: 0.6395 - out_1_loss: 0.6688 - out_2_loss: 0.6884 - out_3_loss: 0.7017 - out_4_loss: 0.5936 - out_5_loss: 0.6129 - out_6_loss: 0.6300 - out_7_loss: 0.4571 - out_8_loss: 0.7747 - out_9_loss: 0.5957 - final_output_loss: 6.2325 - out_0_acc: 5.3342e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 4.8008e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 4.2673e-05 - out_5_acc: 5.3342e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 4.2673e-05 - out_8_acc: 3.7339e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1248 - val_loss: 9.3170 - val_out_0_loss: 0.1169 - val_out_1_loss: 0.0870 - val_out_2_loss: 0.1051 - val_out_3_loss: 0.1594 - val_out_4_loss: 0.1490 - val_out_5_loss: 0.0918 - val_out_6_loss: 0.0572 - val_out_7_loss: 0.1584 - val_out_8_loss: 0.0915 - val_out_9_loss: 0.1335 - val_final_output_loss: 8.1671 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 53/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.7273 - out_0_loss: 0.6370 - out_1_loss: 0.6566 - out_2_loss: 0.6870 - out_3_loss: 0.6800 - out_4_loss: 0.5915 - out_5_loss: 0.6073 - out_6_loss: 0.6217 - out_7_loss: 0.4488 - out_8_loss: 0.7667 - out_9_loss: 0.5886 - final_output_loss: 6.4421 - out_0_acc: 5.3342e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 4.8008e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 4.2673e-05 - out_6_acc: 3.7339e-05 - out_7_acc: 5.3342e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1109 - val_loss: 8.6981 - val_out_0_loss: 0.0924 - val_out_1_loss: 0.0826 - val_out_2_loss: 0.1094 - val_out_3_loss: 0.1485 - val_out_4_loss: 0.1451 - val_out_5_loss: 0.0651 - val_out_6_loss: 0.0596 - val_out_7_loss: 0.1793 - val_out_8_loss: 0.0972 - val_out_9_loss: 0.1468 - val_final_output_loss: 7.5721 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 54/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.4493 - out_0_loss: 0.6227 - out_1_loss: 0.6410 - out_2_loss: 0.6748 - out_3_loss: 0.6634 - out_4_loss: 0.5899 - out_5_loss: 0.5969 - out_6_loss: 0.6083 - out_7_loss: 0.4448 - out_8_loss: 0.7414 - out_9_loss: 0.5780 - final_output_loss: 6.2880 - out_0_acc: 5.8676e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 4.2673e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 4.8008e-05 - out_6_acc: 4.2673e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1354 - val_loss: 9.2936 - val_out_0_loss: 0.0763 - val_out_1_loss: 0.0688 - val_out_2_loss: 0.0893 - val_out_3_loss: 0.1175 - val_out_4_loss: 0.1348 - val_out_5_loss: 0.0648 - val_out_6_loss: 0.0759 - val_out_7_loss: 0.1959 - val_out_8_loss: 0.1372 - val_out_9_loss: 0.1619 - val_final_output_loss: 8.1712 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 55/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.3851 - out_0_loss: 0.6140 - out_1_loss: 0.6444 - out_2_loss: 0.6613 - out_3_loss: 0.6603 - out_4_loss: 0.5762 - out_5_loss: 0.5915 - out_6_loss: 0.6018 - out_7_loss: 0.4368 - out_8_loss: 0.7336 - out_9_loss: 0.5712 - final_output_loss: 6.2941 - out_0_acc: 4.2673e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 5.3342e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1311 - val_loss: 8.6225 - val_out_0_loss: 0.0952 - val_out_1_loss: 0.0631 - val_out_2_loss: 0.1078 - val_out_3_loss: 0.1352 - val_out_4_loss: 0.1312 - val_out_5_loss: 0.0646 - val_out_6_loss: 0.0486 - val_out_7_loss: 0.1643 - val_out_8_loss: 0.1012 - val_out_9_loss: 0.1254 - val_final_output_loss: 7.5859 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 6.9999998231651255e-06.\n",
            "Epoch 56/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.4160 - out_0_loss: 0.6072 - out_1_loss: 0.6295 - out_2_loss: 0.6652 - out_3_loss: 0.6566 - out_4_loss: 0.5715 - out_5_loss: 0.5784 - out_6_loss: 0.5899 - out_7_loss: 0.4393 - out_8_loss: 0.7298 - out_9_loss: 0.5557 - final_output_loss: 6.3930 - out_0_acc: 4.8008e-05 - out_1_acc: 5.8676e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 4.8008e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 5.3342e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1243 - val_loss: 8.7110 - val_out_0_loss: 0.0831 - val_out_1_loss: 0.0750 - val_out_2_loss: 0.1266 - val_out_3_loss: 0.1338 - val_out_4_loss: 0.1584 - val_out_5_loss: 0.0590 - val_out_6_loss: 0.0673 - val_out_7_loss: 0.1770 - val_out_8_loss: 0.0922 - val_out_9_loss: 0.1682 - val_final_output_loss: 7.5703 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 57/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.2666 - out_0_loss: 0.6044 - out_1_loss: 0.6254 - out_2_loss: 0.6502 - out_3_loss: 0.6511 - out_4_loss: 0.5631 - out_5_loss: 0.5780 - out_6_loss: 0.5841 - out_7_loss: 0.4372 - out_8_loss: 0.7269 - out_9_loss: 0.5566 - final_output_loss: 6.2896 - out_0_acc: 5.3342e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 5.3342e-05 - out_8_acc: 3.7339e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1152 - val_loss: 8.5936 - val_out_0_loss: 0.0821 - val_out_1_loss: 0.0635 - val_out_2_loss: 0.0991 - val_out_3_loss: 0.1173 - val_out_4_loss: 0.1332 - val_out_5_loss: 0.0485 - val_out_6_loss: 0.0720 - val_out_7_loss: 0.1772 - val_out_8_loss: 0.0928 - val_out_9_loss: 0.1515 - val_final_output_loss: 7.5564 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 58/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.0061 - out_0_loss: 0.5978 - out_1_loss: 0.6214 - out_2_loss: 0.6483 - out_3_loss: 0.6453 - out_4_loss: 0.5559 - out_5_loss: 0.5722 - out_6_loss: 0.5755 - out_7_loss: 0.4257 - out_8_loss: 0.7146 - out_9_loss: 0.5518 - final_output_loss: 6.0975 - out_0_acc: 4.8008e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 4.8008e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1143 - val_loss: 8.6002 - val_out_0_loss: 0.0837 - val_out_1_loss: 0.0427 - val_out_2_loss: 0.0928 - val_out_3_loss: 0.1553 - val_out_4_loss: 0.1315 - val_out_5_loss: 0.0926 - val_out_6_loss: 0.0683 - val_out_7_loss: 0.1657 - val_out_8_loss: 0.0826 - val_out_9_loss: 0.1389 - val_final_output_loss: 7.5460 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 59/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.2163 - out_0_loss: 0.5939 - out_1_loss: 0.6091 - out_2_loss: 0.6382 - out_3_loss: 0.6394 - out_4_loss: 0.5553 - out_5_loss: 0.5664 - out_6_loss: 0.5692 - out_7_loss: 0.4259 - out_8_loss: 0.7056 - out_9_loss: 0.5402 - final_output_loss: 6.3731 - out_0_acc: 5.8676e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 5.8676e-05 - out_7_acc: 5.3342e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1224 - val_loss: 8.7892 - val_out_0_loss: 0.0761 - val_out_1_loss: 0.0782 - val_out_2_loss: 0.1060 - val_out_3_loss: 0.1578 - val_out_4_loss: 0.1561 - val_out_5_loss: 0.1032 - val_out_6_loss: 0.0908 - val_out_7_loss: 0.1979 - val_out_8_loss: 0.1204 - val_out_9_loss: 0.1517 - val_final_output_loss: 7.5512 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 60/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.9910 - out_0_loss: 0.5816 - out_1_loss: 0.6056 - out_2_loss: 0.6357 - out_3_loss: 0.6310 - out_4_loss: 0.5480 - out_5_loss: 0.5636 - out_6_loss: 0.5637 - out_7_loss: 0.4200 - out_8_loss: 0.7039 - out_9_loss: 0.5402 - final_output_loss: 6.1977 - out_0_acc: 6.4010e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 3.7339e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1114 - val_loss: 8.6631 - val_out_0_loss: 0.0995 - val_out_1_loss: 0.0851 - val_out_2_loss: 0.1095 - val_out_3_loss: 0.1326 - val_out_4_loss: 0.1437 - val_out_5_loss: 0.0759 - val_out_6_loss: 0.0612 - val_out_7_loss: 0.1714 - val_out_8_loss: 0.1178 - val_out_9_loss: 0.1337 - val_final_output_loss: 7.5328 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 61/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.0125 - out_0_loss: 0.5803 - out_1_loss: 0.6002 - out_2_loss: 0.6287 - out_3_loss: 0.6257 - out_4_loss: 0.5433 - out_5_loss: 0.5547 - out_6_loss: 0.5564 - out_7_loss: 0.4184 - out_8_loss: 0.6998 - out_9_loss: 0.5296 - final_output_loss: 6.2754 - out_0_acc: 5.3342e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 4.8008e-05 - out_4_acc: 4.2673e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1133 - val_loss: 8.6405 - val_out_0_loss: 0.0863 - val_out_1_loss: 0.0855 - val_out_2_loss: 0.1114 - val_out_3_loss: 0.1606 - val_out_4_loss: 0.1451 - val_out_5_loss: 0.0717 - val_out_6_loss: 0.0700 - val_out_7_loss: 0.1645 - val_out_8_loss: 0.0859 - val_out_9_loss: 0.1336 - val_final_output_loss: 7.5259 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 62/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 12.0414 - out_0_loss: 0.5765 - out_1_loss: 0.5967 - out_2_loss: 0.6223 - out_3_loss: 0.6277 - out_4_loss: 0.5352 - out_5_loss: 0.5470 - out_6_loss: 0.5534 - out_7_loss: 0.4146 - out_8_loss: 0.6879 - out_9_loss: 0.5270 - final_output_loss: 6.3530 - out_0_acc: 6.4010e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 4.2673e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1205 - val_loss: 8.5645 - val_out_0_loss: 0.0917 - val_out_1_loss: 0.0533 - val_out_2_loss: 0.1190 - val_out_3_loss: 0.1087 - val_out_4_loss: 0.1305 - val_out_5_loss: 0.0664 - val_out_6_loss: 0.0459 - val_out_7_loss: 0.1716 - val_out_8_loss: 0.1038 - val_out_9_loss: 0.1455 - val_final_output_loss: 7.5279 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 63/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.8089 - out_0_loss: 0.5660 - out_1_loss: 0.5907 - out_2_loss: 0.6112 - out_3_loss: 0.6204 - out_4_loss: 0.5331 - out_5_loss: 0.5471 - out_6_loss: 0.5476 - out_7_loss: 0.4102 - out_8_loss: 0.6791 - out_9_loss: 0.5215 - final_output_loss: 6.1820 - out_0_acc: 6.4010e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 4.8008e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 5.8676e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 4.2673e-05 - out_9_acc: 4.8008e-05 - final_output_acc: 0.1143 - val_loss: 8.6301 - val_out_0_loss: 0.0773 - val_out_1_loss: 0.0441 - val_out_2_loss: 0.0875 - val_out_3_loss: 0.1395 - val_out_4_loss: 0.1410 - val_out_5_loss: 0.0904 - val_out_6_loss: 0.0610 - val_out_7_loss: 0.1780 - val_out_8_loss: 0.1173 - val_out_9_loss: 0.1645 - val_final_output_loss: 7.5296 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 64/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.9131 - out_0_loss: 0.5647 - out_1_loss: 0.5756 - out_2_loss: 0.6098 - out_3_loss: 0.6122 - out_4_loss: 0.5259 - out_5_loss: 0.5404 - out_6_loss: 0.5402 - out_7_loss: 0.4068 - out_8_loss: 0.6767 - out_9_loss: 0.5188 - final_output_loss: 6.3421 - out_0_acc: 5.8676e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 4.2673e-05 - out_6_acc: 4.8008e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1272 - val_loss: 8.5308 - val_out_0_loss: 0.0884 - val_out_1_loss: 0.0485 - val_out_2_loss: 0.0987 - val_out_3_loss: 0.1189 - val_out_4_loss: 0.1243 - val_out_5_loss: 0.0840 - val_out_6_loss: 0.0732 - val_out_7_loss: 0.1516 - val_out_8_loss: 0.0897 - val_out_9_loss: 0.1152 - val_final_output_loss: 7.5382 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 65/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.8133 - out_0_loss: 0.5625 - out_1_loss: 0.5805 - out_2_loss: 0.6060 - out_3_loss: 0.6115 - out_4_loss: 0.5174 - out_5_loss: 0.5367 - out_6_loss: 0.5291 - out_7_loss: 0.4041 - out_8_loss: 0.6676 - out_9_loss: 0.5114 - final_output_loss: 6.2865 - out_0_acc: 6.4010e-05 - out_1_acc: 5.8676e-05 - out_2_acc: 4.8008e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1051 - val_loss: 8.6784 - val_out_0_loss: 0.1039 - val_out_1_loss: 0.0819 - val_out_2_loss: 0.0845 - val_out_3_loss: 0.1229 - val_out_4_loss: 0.1363 - val_out_5_loss: 0.0694 - val_out_6_loss: 0.0924 - val_out_7_loss: 0.1815 - val_out_8_loss: 0.1180 - val_out_9_loss: 0.1509 - val_final_output_loss: 7.5367 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 66/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.7635 - out_0_loss: 0.5544 - out_1_loss: 0.5712 - out_2_loss: 0.5973 - out_3_loss: 0.6010 - out_4_loss: 0.5195 - out_5_loss: 0.5332 - out_6_loss: 0.5215 - out_7_loss: 0.3997 - out_8_loss: 0.6661 - out_9_loss: 0.5051 - final_output_loss: 6.2946 - out_0_acc: 6.4010e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 4.2673e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1195 - val_loss: 8.6049 - val_out_0_loss: 0.0870 - val_out_1_loss: 0.0680 - val_out_2_loss: 0.0871 - val_out_3_loss: 0.1377 - val_out_4_loss: 0.1412 - val_out_5_loss: 0.0549 - val_out_6_loss: 0.0831 - val_out_7_loss: 0.1620 - val_out_8_loss: 0.1219 - val_out_9_loss: 0.1180 - val_final_output_loss: 7.5439 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 67/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.6238 - out_0_loss: 0.5476 - out_1_loss: 0.5671 - out_2_loss: 0.5940 - out_3_loss: 0.6022 - out_4_loss: 0.5116 - out_5_loss: 0.5262 - out_6_loss: 0.5180 - out_7_loss: 0.3995 - out_8_loss: 0.6586 - out_9_loss: 0.5046 - final_output_loss: 6.1944 - out_0_acc: 6.4010e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 4.8008e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 4.8008e-05 - out_6_acc: 5.8676e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1234 - val_loss: 8.6019 - val_out_0_loss: 0.0954 - val_out_1_loss: 0.0498 - val_out_2_loss: 0.1015 - val_out_3_loss: 0.1249 - val_out_4_loss: 0.1426 - val_out_5_loss: 0.0766 - val_out_6_loss: 0.0862 - val_out_7_loss: 0.1626 - val_out_8_loss: 0.0991 - val_out_9_loss: 0.1237 - val_final_output_loss: 7.5395 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 68/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.4987 - out_0_loss: 0.5430 - out_1_loss: 0.5580 - out_2_loss: 0.5794 - out_3_loss: 0.5890 - out_4_loss: 0.5160 - out_5_loss: 0.5199 - out_6_loss: 0.5163 - out_7_loss: 0.3913 - out_8_loss: 0.6528 - out_9_loss: 0.4957 - final_output_loss: 6.1371 - out_0_acc: 5.3342e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 5.3342e-05 - out_6_acc: 5.8676e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1200 - val_loss: 8.5721 - val_out_0_loss: 0.0998 - val_out_1_loss: 0.0653 - val_out_2_loss: 0.1046 - val_out_3_loss: 0.1276 - val_out_4_loss: 0.1259 - val_out_5_loss: 0.0364 - val_out_6_loss: 0.0655 - val_out_7_loss: 0.1793 - val_out_8_loss: 0.1079 - val_out_9_loss: 0.1223 - val_final_output_loss: 7.5375 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 69/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.5938 - out_0_loss: 0.5412 - out_1_loss: 0.5538 - out_2_loss: 0.5843 - out_3_loss: 0.5962 - out_4_loss: 0.5001 - out_5_loss: 0.5151 - out_6_loss: 0.5054 - out_7_loss: 0.3899 - out_8_loss: 0.6461 - out_9_loss: 0.4935 - final_output_loss: 6.2682 - out_0_acc: 5.8676e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 4.8008e-05 - out_4_acc: 4.8008e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 5.8676e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1243 - val_loss: 8.5154 - val_out_0_loss: 0.0703 - val_out_1_loss: 0.0516 - val_out_2_loss: 0.1097 - val_out_3_loss: 0.1026 - val_out_4_loss: 0.1066 - val_out_5_loss: 0.0754 - val_out_6_loss: 0.0759 - val_out_7_loss: 0.1503 - val_out_8_loss: 0.1119 - val_out_9_loss: 0.1352 - val_final_output_loss: 7.5259 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 70/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.4678 - out_0_loss: 0.5294 - out_1_loss: 0.5518 - out_2_loss: 0.5777 - out_3_loss: 0.5823 - out_4_loss: 0.4987 - out_5_loss: 0.5129 - out_6_loss: 0.4995 - out_7_loss: 0.3868 - out_8_loss: 0.6409 - out_9_loss: 0.4887 - final_output_loss: 6.1991 - out_0_acc: 5.8676e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 4.2673e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1224 - val_loss: 8.5756 - val_out_0_loss: 0.0838 - val_out_1_loss: 0.0575 - val_out_2_loss: 0.0730 - val_out_3_loss: 0.1328 - val_out_4_loss: 0.1270 - val_out_5_loss: 0.0764 - val_out_6_loss: 0.0813 - val_out_7_loss: 0.1619 - val_out_8_loss: 0.1008 - val_out_9_loss: 0.1510 - val_final_output_loss: 7.5301 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 71/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.6691 - out_0_loss: 0.5299 - out_1_loss: 0.5424 - out_2_loss: 0.5671 - out_3_loss: 0.5839 - out_4_loss: 0.4932 - out_5_loss: 0.5058 - out_6_loss: 0.5000 - out_7_loss: 0.3834 - out_8_loss: 0.6383 - out_9_loss: 0.4794 - final_output_loss: 6.4456 - out_0_acc: 4.8008e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 4.8008e-05 - out_3_acc: 4.8008e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1191 - val_loss: 8.5546 - val_out_0_loss: 0.0812 - val_out_1_loss: 0.0751 - val_out_2_loss: 0.0936 - val_out_3_loss: 0.1094 - val_out_4_loss: 0.1205 - val_out_5_loss: 0.0687 - val_out_6_loss: 0.0788 - val_out_7_loss: 0.1640 - val_out_8_loss: 0.0974 - val_out_9_loss: 0.1325 - val_final_output_loss: 7.5335 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 72/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.4375 - out_0_loss: 0.5210 - out_1_loss: 0.5352 - out_2_loss: 0.5640 - out_3_loss: 0.5728 - out_4_loss: 0.4917 - out_5_loss: 0.5035 - out_6_loss: 0.4861 - out_7_loss: 0.3804 - out_8_loss: 0.6155 - out_9_loss: 0.4729 - final_output_loss: 6.2942 - out_0_acc: 5.8676e-05 - out_1_acc: 4.2673e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 5.8676e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 4.2673e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1287 - val_loss: 8.5922 - val_out_0_loss: 0.0898 - val_out_1_loss: 0.0703 - val_out_2_loss: 0.0853 - val_out_3_loss: 0.1270 - val_out_4_loss: 0.1189 - val_out_5_loss: 0.0606 - val_out_6_loss: 0.0776 - val_out_7_loss: 0.1859 - val_out_8_loss: 0.1084 - val_out_9_loss: 0.1376 - val_final_output_loss: 7.5310 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 73/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.3398 - out_0_loss: 0.5196 - out_1_loss: 0.5338 - out_2_loss: 0.5595 - out_3_loss: 0.5701 - out_4_loss: 0.4800 - out_5_loss: 0.4980 - out_6_loss: 0.4820 - out_7_loss: 0.3779 - out_8_loss: 0.6132 - out_9_loss: 0.4667 - final_output_loss: 6.2388 - out_0_acc: 6.4010e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 4.8008e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 4.8008e-05 - final_output_acc: 0.1200 - val_loss: 8.0922 - val_out_0_loss: 0.0731 - val_out_1_loss: 0.0640 - val_out_2_loss: 0.0985 - val_out_3_loss: 0.1295 - val_out_4_loss: 0.1217 - val_out_5_loss: 0.0882 - val_out_6_loss: 0.0691 - val_out_7_loss: 0.1608 - val_out_8_loss: 0.1102 - val_out_9_loss: 0.1183 - val_final_output_loss: 7.0589 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 74/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.3054 - out_0_loss: 0.5128 - out_1_loss: 0.5223 - out_2_loss: 0.5537 - out_3_loss: 0.5627 - out_4_loss: 0.4816 - out_5_loss: 0.4927 - out_6_loss: 0.4807 - out_7_loss: 0.3736 - out_8_loss: 0.6050 - out_9_loss: 0.4669 - final_output_loss: 6.2533 - out_0_acc: 5.3342e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1152 - val_loss: 8.7448 - val_out_0_loss: 0.1011 - val_out_1_loss: 0.0750 - val_out_2_loss: 0.1193 - val_out_3_loss: 0.1323 - val_out_4_loss: 0.1439 - val_out_5_loss: 0.0814 - val_out_6_loss: 0.1077 - val_out_7_loss: 0.1735 - val_out_8_loss: 0.1108 - val_out_9_loss: 0.1670 - val_final_output_loss: 7.5328 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 75/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.0847 - out_0_loss: 0.5137 - out_1_loss: 0.5122 - out_2_loss: 0.5393 - out_3_loss: 0.5616 - out_4_loss: 0.4762 - out_5_loss: 0.4913 - out_6_loss: 0.4721 - out_7_loss: 0.3736 - out_8_loss: 0.6035 - out_9_loss: 0.4578 - final_output_loss: 6.0835 - out_0_acc: 6.4010e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 4.8008e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 5.3342e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1152 - val_loss: 7.6154 - val_out_0_loss: 0.0946 - val_out_1_loss: 0.0764 - val_out_2_loss: 0.1095 - val_out_3_loss: 0.1513 - val_out_4_loss: 0.1460 - val_out_5_loss: 0.0813 - val_out_6_loss: 0.0867 - val_out_7_loss: 0.1822 - val_out_8_loss: 0.1320 - val_out_9_loss: 0.1239 - val_final_output_loss: 6.4314 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 76/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.2170 - out_0_loss: 0.5069 - out_1_loss: 0.5147 - out_2_loss: 0.5323 - out_3_loss: 0.5598 - out_4_loss: 0.4715 - out_5_loss: 0.4838 - out_6_loss: 0.4667 - out_7_loss: 0.3689 - out_8_loss: 0.5993 - out_9_loss: 0.4517 - final_output_loss: 6.2615 - out_0_acc: 4.2673e-05 - out_1_acc: 5.8676e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1248 - val_loss: 7.5007 - val_out_0_loss: 0.1058 - val_out_1_loss: 0.0810 - val_out_2_loss: 0.0887 - val_out_3_loss: 0.1265 - val_out_4_loss: 0.1231 - val_out_5_loss: 0.0830 - val_out_6_loss: 0.0763 - val_out_7_loss: 0.1720 - val_out_8_loss: 0.0795 - val_out_9_loss: 0.1274 - val_final_output_loss: 6.4375 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 77/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.0457 - out_0_loss: 0.5021 - out_1_loss: 0.5053 - out_2_loss: 0.5302 - out_3_loss: 0.5500 - out_4_loss: 0.4635 - out_5_loss: 0.4819 - out_6_loss: 0.4689 - out_7_loss: 0.3689 - out_8_loss: 0.5923 - out_9_loss: 0.4512 - final_output_loss: 6.1313 - out_0_acc: 4.8008e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 5.8676e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 4.8008e-05 - final_output_acc: 0.1138 - val_loss: 7.5374 - val_out_0_loss: 0.0900 - val_out_1_loss: 0.0845 - val_out_2_loss: 0.0802 - val_out_3_loss: 0.1433 - val_out_4_loss: 0.1409 - val_out_5_loss: 0.0749 - val_out_6_loss: 0.0816 - val_out_7_loss: 0.1674 - val_out_8_loss: 0.0986 - val_out_9_loss: 0.1401 - val_final_output_loss: 6.4358 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 78/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 11.0360 - out_0_loss: 0.4966 - out_1_loss: 0.5021 - out_2_loss: 0.5253 - out_3_loss: 0.5466 - out_4_loss: 0.4626 - out_5_loss: 0.4722 - out_6_loss: 0.4589 - out_7_loss: 0.3632 - out_8_loss: 0.5818 - out_9_loss: 0.4452 - final_output_loss: 6.1816 - out_0_acc: 7.4679e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 5.3342e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1272 - val_loss: 7.4890 - val_out_0_loss: 0.1056 - val_out_1_loss: 0.0705 - val_out_2_loss: 0.1005 - val_out_3_loss: 0.1311 - val_out_4_loss: 0.1179 - val_out_5_loss: 0.0535 - val_out_6_loss: 0.0895 - val_out_7_loss: 0.1839 - val_out_8_loss: 0.1011 - val_out_9_loss: 0.1271 - val_final_output_loss: 6.4083 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 79/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.7102 - out_0_loss: 0.4915 - out_1_loss: 0.4956 - out_2_loss: 0.5290 - out_3_loss: 0.5402 - out_4_loss: 0.4646 - out_5_loss: 0.4700 - out_6_loss: 0.4482 - out_7_loss: 0.3595 - out_8_loss: 0.5799 - out_9_loss: 0.4369 - final_output_loss: 5.8947 - out_0_acc: 5.3342e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1167 - val_loss: 7.4976 - val_out_0_loss: 0.0982 - val_out_1_loss: 0.0778 - val_out_2_loss: 0.1427 - val_out_3_loss: 0.1422 - val_out_4_loss: 0.1101 - val_out_5_loss: 0.0595 - val_out_6_loss: 0.0816 - val_out_7_loss: 0.1569 - val_out_8_loss: 0.0906 - val_out_9_loss: 0.1260 - val_final_output_loss: 6.4120 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 80/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.8165 - out_0_loss: 0.4837 - out_1_loss: 0.4925 - out_2_loss: 0.5153 - out_3_loss: 0.5352 - out_4_loss: 0.4540 - out_5_loss: 0.4623 - out_6_loss: 0.4472 - out_7_loss: 0.3542 - out_8_loss: 0.5764 - out_9_loss: 0.4336 - final_output_loss: 6.0620 - out_0_acc: 6.4010e-05 - out_1_acc: 5.3342e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 4.2673e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1152 - val_loss: 6.3586 - val_out_0_loss: 0.0709 - val_out_1_loss: 0.0648 - val_out_2_loss: 0.0829 - val_out_3_loss: 0.1138 - val_out_4_loss: 0.1067 - val_out_5_loss: 0.0462 - val_out_6_loss: 0.0456 - val_out_7_loss: 0.1610 - val_out_8_loss: 0.1029 - val_out_9_loss: 0.1262 - val_final_output_loss: 5.4376 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 81/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.5978 - out_0_loss: 0.4771 - out_1_loss: 0.4898 - out_2_loss: 0.5158 - out_3_loss: 0.5375 - out_4_loss: 0.4503 - out_5_loss: 0.4611 - out_6_loss: 0.4405 - out_7_loss: 0.3547 - out_8_loss: 0.5664 - out_9_loss: 0.4290 - final_output_loss: 5.8758 - out_0_acc: 6.4010e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 3.2005e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1229 - val_loss: 6.4365 - val_out_0_loss: 0.0752 - val_out_1_loss: 0.0632 - val_out_2_loss: 0.1106 - val_out_3_loss: 0.1325 - val_out_4_loss: 0.1078 - val_out_5_loss: 0.0498 - val_out_6_loss: 0.0757 - val_out_7_loss: 0.1553 - val_out_8_loss: 0.1032 - val_out_9_loss: 0.1322 - val_final_output_loss: 5.4311 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 82/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.6428 - out_0_loss: 0.4773 - out_1_loss: 0.4806 - out_2_loss: 0.5074 - out_3_loss: 0.5347 - out_4_loss: 0.4453 - out_5_loss: 0.4616 - out_6_loss: 0.4360 - out_7_loss: 0.3498 - out_8_loss: 0.5589 - out_9_loss: 0.4305 - final_output_loss: 5.9606 - out_0_acc: 4.8008e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 4.8008e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 5.8676e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1272 - val_loss: 6.4630 - val_out_0_loss: 0.0916 - val_out_1_loss: 0.0799 - val_out_2_loss: 0.1099 - val_out_3_loss: 0.1396 - val_out_4_loss: 0.1187 - val_out_5_loss: 0.0463 - val_out_6_loss: 0.0748 - val_out_7_loss: 0.1728 - val_out_8_loss: 0.1043 - val_out_9_loss: 0.1157 - val_final_output_loss: 5.4094 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 83/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.6667 - out_0_loss: 0.4706 - out_1_loss: 0.4781 - out_2_loss: 0.5003 - out_3_loss: 0.5309 - out_4_loss: 0.4409 - out_5_loss: 0.4552 - out_6_loss: 0.4356 - out_7_loss: 0.3474 - out_8_loss: 0.5531 - out_9_loss: 0.4214 - final_output_loss: 6.0331 - out_0_acc: 6.4010e-05 - out_1_acc: 3.7339e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 5.3342e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1186 - val_loss: 6.3870 - val_out_0_loss: 0.1079 - val_out_1_loss: 0.0742 - val_out_2_loss: 0.0947 - val_out_3_loss: 0.1374 - val_out_4_loss: 0.1143 - val_out_5_loss: 0.0718 - val_out_6_loss: 0.0821 - val_out_7_loss: 0.1335 - val_out_8_loss: 0.0968 - val_out_9_loss: 0.1086 - val_final_output_loss: 5.3656 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 84/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.5798 - out_0_loss: 0.4664 - out_1_loss: 0.4732 - out_2_loss: 0.4979 - out_3_loss: 0.5176 - out_4_loss: 0.4405 - out_5_loss: 0.4501 - out_6_loss: 0.4270 - out_7_loss: 0.3490 - out_8_loss: 0.5452 - out_9_loss: 0.4214 - final_output_loss: 5.9914 - out_0_acc: 5.3342e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1099 - val_loss: 6.2278 - val_out_0_loss: 0.0811 - val_out_1_loss: 0.0589 - val_out_2_loss: 0.1040 - val_out_3_loss: 0.1114 - val_out_4_loss: 0.1061 - val_out_5_loss: 0.0297 - val_out_6_loss: 0.0780 - val_out_7_loss: 0.1428 - val_out_8_loss: 0.1094 - val_out_9_loss: 0.1224 - val_final_output_loss: 5.2840 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 85/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.3091 - out_0_loss: 0.4657 - out_1_loss: 0.4650 - out_2_loss: 0.4968 - out_3_loss: 0.5171 - out_4_loss: 0.4313 - out_5_loss: 0.4431 - out_6_loss: 0.4238 - out_7_loss: 0.3445 - out_8_loss: 0.5434 - out_9_loss: 0.4184 - final_output_loss: 5.7600 - out_0_acc: 6.4010e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1200 - val_loss: 6.6810 - val_out_0_loss: 0.1166 - val_out_1_loss: 0.0686 - val_out_2_loss: 0.0887 - val_out_3_loss: 0.1394 - val_out_4_loss: 0.1287 - val_out_5_loss: 0.0713 - val_out_6_loss: 0.0982 - val_out_7_loss: 0.1806 - val_out_8_loss: 0.1249 - val_out_9_loss: 0.1474 - val_final_output_loss: 5.5166 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 86/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.6106 - out_0_loss: 0.4584 - out_1_loss: 0.4709 - out_2_loss: 0.4887 - out_3_loss: 0.5135 - out_4_loss: 0.4258 - out_5_loss: 0.4437 - out_6_loss: 0.4186 - out_7_loss: 0.3414 - out_8_loss: 0.5413 - out_9_loss: 0.4125 - final_output_loss: 6.0958 - out_0_acc: 5.8676e-05 - out_1_acc: 5.8676e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 5.8676e-05 - final_output_acc: 0.1339 - val_loss: 6.4849 - val_out_0_loss: 0.0956 - val_out_1_loss: 0.0722 - val_out_2_loss: 0.1060 - val_out_3_loss: 0.1552 - val_out_4_loss: 0.1336 - val_out_5_loss: 0.0643 - val_out_6_loss: 0.1031 - val_out_7_loss: 0.1678 - val_out_8_loss: 0.1262 - val_out_9_loss: 0.1328 - val_final_output_loss: 5.3281 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 87/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.4481 - out_0_loss: 0.4513 - out_1_loss: 0.4591 - out_2_loss: 0.4874 - out_3_loss: 0.5095 - out_4_loss: 0.4311 - out_5_loss: 0.4379 - out_6_loss: 0.4111 - out_7_loss: 0.3362 - out_8_loss: 0.5317 - out_9_loss: 0.4062 - final_output_loss: 5.9867 - out_0_acc: 6.4010e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1195 - val_loss: 6.3262 - val_out_0_loss: 0.0890 - val_out_1_loss: 0.0623 - val_out_2_loss: 0.0893 - val_out_3_loss: 0.1147 - val_out_4_loss: 0.0908 - val_out_5_loss: 0.0774 - val_out_6_loss: 0.0947 - val_out_7_loss: 0.1565 - val_out_8_loss: 0.1118 - val_out_9_loss: 0.1236 - val_final_output_loss: 5.3162 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 88/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.4297 - out_0_loss: 0.4506 - out_1_loss: 0.4542 - out_2_loss: 0.4834 - out_3_loss: 0.4997 - out_4_loss: 0.4247 - out_5_loss: 0.4328 - out_6_loss: 0.4097 - out_7_loss: 0.3374 - out_8_loss: 0.5319 - out_9_loss: 0.4036 - final_output_loss: 6.0017 - out_0_acc: 6.4010e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1263 - val_loss: 6.2572 - val_out_0_loss: 0.0888 - val_out_1_loss: 0.0608 - val_out_2_loss: 0.0739 - val_out_3_loss: 0.1180 - val_out_4_loss: 0.0987 - val_out_5_loss: 0.0613 - val_out_6_loss: 0.0809 - val_out_7_loss: 0.1629 - val_out_8_loss: 0.1084 - val_out_9_loss: 0.1214 - val_final_output_loss: 5.2820 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 89/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.1382 - out_0_loss: 0.4436 - out_1_loss: 0.4536 - out_2_loss: 0.4700 - out_3_loss: 0.5015 - out_4_loss: 0.4159 - out_5_loss: 0.4302 - out_6_loss: 0.3973 - out_7_loss: 0.3330 - out_8_loss: 0.5172 - out_9_loss: 0.3981 - final_output_loss: 5.7779 - out_0_acc: 6.9344e-05 - out_1_acc: 5.8676e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1195 - val_loss: 6.3268 - val_out_0_loss: 0.0901 - val_out_1_loss: 0.0861 - val_out_2_loss: 0.0902 - val_out_3_loss: 0.1222 - val_out_4_loss: 0.1063 - val_out_5_loss: 0.0674 - val_out_6_loss: 0.1095 - val_out_7_loss: 0.1478 - val_out_8_loss: 0.1146 - val_out_9_loss: 0.1184 - val_final_output_loss: 5.2741 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 90/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.4391 - out_0_loss: 0.4402 - out_1_loss: 0.4452 - out_2_loss: 0.4694 - out_3_loss: 0.4959 - out_4_loss: 0.4148 - out_5_loss: 0.4245 - out_6_loss: 0.3980 - out_7_loss: 0.3318 - out_8_loss: 0.5113 - out_9_loss: 0.3947 - final_output_loss: 6.1132 - out_0_acc: 6.4010e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 4.2673e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1138 - val_loss: 6.3147 - val_out_0_loss: 0.0863 - val_out_1_loss: 0.0822 - val_out_2_loss: 0.0943 - val_out_3_loss: 0.1361 - val_out_4_loss: 0.0951 - val_out_5_loss: 0.0654 - val_out_6_loss: 0.0936 - val_out_7_loss: 0.1621 - val_out_8_loss: 0.1102 - val_out_9_loss: 0.1269 - val_final_output_loss: 5.2622 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 91/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.1846 - out_0_loss: 0.4422 - out_1_loss: 0.4449 - out_2_loss: 0.4650 - out_3_loss: 0.4947 - out_4_loss: 0.4068 - out_5_loss: 0.4181 - out_6_loss: 0.3937 - out_7_loss: 0.3324 - out_8_loss: 0.5090 - out_9_loss: 0.3915 - final_output_loss: 5.8864 - out_0_acc: 7.4679e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 5.3342e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1263 - val_loss: 6.3743 - val_out_0_loss: 0.0825 - val_out_1_loss: 0.0684 - val_out_2_loss: 0.1090 - val_out_3_loss: 0.1545 - val_out_4_loss: 0.1360 - val_out_5_loss: 0.0651 - val_out_6_loss: 0.1016 - val_out_7_loss: 0.1696 - val_out_8_loss: 0.1011 - val_out_9_loss: 0.1278 - val_final_output_loss: 5.2586 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 92/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.2224 - out_0_loss: 0.4363 - out_1_loss: 0.4361 - out_2_loss: 0.4628 - out_3_loss: 0.4909 - out_4_loss: 0.4102 - out_5_loss: 0.4192 - out_6_loss: 0.3885 - out_7_loss: 0.3264 - out_8_loss: 0.4972 - out_9_loss: 0.3911 - final_output_loss: 5.9638 - out_0_acc: 5.8676e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1171 - val_loss: 6.3463 - val_out_0_loss: 0.1082 - val_out_1_loss: 0.0761 - val_out_2_loss: 0.0824 - val_out_3_loss: 0.1293 - val_out_4_loss: 0.1242 - val_out_5_loss: 0.0754 - val_out_6_loss: 0.1007 - val_out_7_loss: 0.1629 - val_out_8_loss: 0.1242 - val_out_9_loss: 0.1201 - val_final_output_loss: 5.2428 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 93/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.0169 - out_0_loss: 0.4267 - out_1_loss: 0.4356 - out_2_loss: 0.4588 - out_3_loss: 0.4824 - out_4_loss: 0.4026 - out_5_loss: 0.4145 - out_6_loss: 0.3884 - out_7_loss: 0.3231 - out_8_loss: 0.4948 - out_9_loss: 0.3790 - final_output_loss: 5.8108 - out_0_acc: 7.4679e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 5.8676e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1114 - val_loss: 6.2367 - val_out_0_loss: 0.0959 - val_out_1_loss: 0.0657 - val_out_2_loss: 0.1011 - val_out_3_loss: 0.1257 - val_out_4_loss: 0.1001 - val_out_5_loss: 0.0554 - val_out_6_loss: 0.0912 - val_out_7_loss: 0.1515 - val_out_8_loss: 0.0866 - val_out_9_loss: 0.1219 - val_final_output_loss: 5.2416 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 94/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.0942 - out_0_loss: 0.4229 - out_1_loss: 0.4245 - out_2_loss: 0.4562 - out_3_loss: 0.4745 - out_4_loss: 0.3968 - out_5_loss: 0.4093 - out_6_loss: 0.3780 - out_7_loss: 0.3200 - out_8_loss: 0.4928 - out_9_loss: 0.3810 - final_output_loss: 5.9383 - out_0_acc: 5.8676e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1152 - val_loss: 6.3973 - val_out_0_loss: 0.1047 - val_out_1_loss: 0.0949 - val_out_2_loss: 0.0980 - val_out_3_loss: 0.1315 - val_out_4_loss: 0.1137 - val_out_5_loss: 0.0832 - val_out_6_loss: 0.1043 - val_out_7_loss: 0.1780 - val_out_8_loss: 0.1120 - val_out_9_loss: 0.1181 - val_final_output_loss: 5.2589 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 95/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.0754 - out_0_loss: 0.4244 - out_1_loss: 0.4221 - out_2_loss: 0.4463 - out_3_loss: 0.4780 - out_4_loss: 0.3945 - out_5_loss: 0.4056 - out_6_loss: 0.3775 - out_7_loss: 0.3171 - out_8_loss: 0.4909 - out_9_loss: 0.3766 - final_output_loss: 5.9424 - out_0_acc: 6.9344e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1272 - val_loss: 6.2424 - val_out_0_loss: 0.0993 - val_out_1_loss: 0.0768 - val_out_2_loss: 0.1017 - val_out_3_loss: 0.1200 - val_out_4_loss: 0.1029 - val_out_5_loss: 0.0539 - val_out_6_loss: 0.0917 - val_out_7_loss: 0.1452 - val_out_8_loss: 0.0953 - val_out_9_loss: 0.1102 - val_final_output_loss: 5.2453 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 96/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 10.1004 - out_0_loss: 0.4169 - out_1_loss: 0.4203 - out_2_loss: 0.4562 - out_3_loss: 0.4771 - out_4_loss: 0.3995 - out_5_loss: 0.4031 - out_6_loss: 0.3742 - out_7_loss: 0.3140 - out_8_loss: 0.4801 - out_9_loss: 0.3745 - final_output_loss: 5.9844 - out_0_acc: 6.4010e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1138 - val_loss: 6.2206 - val_out_0_loss: 0.0999 - val_out_1_loss: 0.0655 - val_out_2_loss: 0.0723 - val_out_3_loss: 0.1067 - val_out_4_loss: 0.0962 - val_out_5_loss: 0.0757 - val_out_6_loss: 0.0979 - val_out_7_loss: 0.1540 - val_out_8_loss: 0.1134 - val_out_9_loss: 0.1207 - val_final_output_loss: 5.2182 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 97/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.9367 - out_0_loss: 0.4155 - out_1_loss: 0.4171 - out_2_loss: 0.4447 - out_3_loss: 0.4739 - out_4_loss: 0.3901 - out_5_loss: 0.4029 - out_6_loss: 0.3689 - out_7_loss: 0.3196 - out_8_loss: 0.4811 - out_9_loss: 0.3720 - final_output_loss: 5.8509 - out_0_acc: 5.8676e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1066 - val_loss: 6.2541 - val_out_0_loss: 0.1103 - val_out_1_loss: 0.0808 - val_out_2_loss: 0.1019 - val_out_3_loss: 0.1354 - val_out_4_loss: 0.1131 - val_out_5_loss: 0.0573 - val_out_6_loss: 0.0861 - val_out_7_loss: 0.1451 - val_out_8_loss: 0.0994 - val_out_9_loss: 0.1061 - val_final_output_loss: 5.2188 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 98/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.6000 - out_0_loss: 0.4115 - out_1_loss: 0.4097 - out_2_loss: 0.4412 - out_3_loss: 0.4704 - out_4_loss: 0.3811 - out_5_loss: 0.3901 - out_6_loss: 0.3645 - out_7_loss: 0.3151 - out_8_loss: 0.4729 - out_9_loss: 0.3646 - final_output_loss: 5.5790 - out_0_acc: 6.9344e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1215 - val_loss: 6.2879 - val_out_0_loss: 0.1016 - val_out_1_loss: 0.0610 - val_out_2_loss: 0.0934 - val_out_3_loss: 0.1159 - val_out_4_loss: 0.1056 - val_out_5_loss: 0.0766 - val_out_6_loss: 0.1162 - val_out_7_loss: 0.1563 - val_out_8_loss: 0.1228 - val_out_9_loss: 0.1401 - val_final_output_loss: 5.1983 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 99/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.7397 - out_0_loss: 0.4070 - out_1_loss: 0.4057 - out_2_loss: 0.4344 - out_3_loss: 0.4640 - out_4_loss: 0.3839 - out_5_loss: 0.3952 - out_6_loss: 0.3624 - out_7_loss: 0.3120 - out_8_loss: 0.4660 - out_9_loss: 0.3616 - final_output_loss: 5.7475 - out_0_acc: 4.8008e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 5.3342e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1099 - val_loss: 5.7902 - val_out_0_loss: 0.0896 - val_out_1_loss: 0.0777 - val_out_2_loss: 0.0742 - val_out_3_loss: 0.1245 - val_out_4_loss: 0.1157 - val_out_5_loss: 0.0735 - val_out_6_loss: 0.1099 - val_out_7_loss: 0.1552 - val_out_8_loss: 0.1095 - val_out_9_loss: 0.1092 - val_final_output_loss: 4.7510 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 100/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.7447 - out_0_loss: 0.4059 - out_1_loss: 0.4052 - out_2_loss: 0.4365 - out_3_loss: 0.4591 - out_4_loss: 0.3803 - out_5_loss: 0.3867 - out_6_loss: 0.3550 - out_7_loss: 0.3096 - out_8_loss: 0.4560 - out_9_loss: 0.3594 - final_output_loss: 5.7912 - out_0_acc: 6.9344e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 5.3342e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 5.8676e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1143 - val_loss: 5.7281 - val_out_0_loss: 0.1086 - val_out_1_loss: 0.0730 - val_out_2_loss: 0.1098 - val_out_3_loss: 0.1253 - val_out_4_loss: 0.0882 - val_out_5_loss: 0.0615 - val_out_6_loss: 0.0790 - val_out_7_loss: 0.1583 - val_out_8_loss: 0.1061 - val_out_9_loss: 0.1245 - val_final_output_loss: 4.6937 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 101/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.6786 - out_0_loss: 0.4005 - out_1_loss: 0.4001 - out_2_loss: 0.4246 - out_3_loss: 0.4542 - out_4_loss: 0.3799 - out_5_loss: 0.3858 - out_6_loss: 0.3538 - out_7_loss: 0.3091 - out_8_loss: 0.4583 - out_9_loss: 0.3567 - final_output_loss: 5.7555 - out_0_acc: 8.0013e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1114 - val_loss: 5.5424 - val_out_0_loss: 0.0996 - val_out_1_loss: 0.0711 - val_out_2_loss: 0.0870 - val_out_3_loss: 0.0896 - val_out_4_loss: 0.0837 - val_out_5_loss: 0.0539 - val_out_6_loss: 0.0725 - val_out_7_loss: 0.1362 - val_out_8_loss: 0.1033 - val_out_9_loss: 0.1168 - val_final_output_loss: 4.6286 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 102/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.7391 - out_0_loss: 0.3976 - out_1_loss: 0.3923 - out_2_loss: 0.4175 - out_3_loss: 0.4596 - out_4_loss: 0.3711 - out_5_loss: 0.3784 - out_6_loss: 0.3476 - out_7_loss: 0.3026 - out_8_loss: 0.4537 - out_9_loss: 0.3526 - final_output_loss: 5.8661 - out_0_acc: 5.3342e-05 - out_1_acc: 5.8676e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1133 - val_loss: 5.6881 - val_out_0_loss: 0.0998 - val_out_1_loss: 0.0604 - val_out_2_loss: 0.0879 - val_out_3_loss: 0.1326 - val_out_4_loss: 0.1005 - val_out_5_loss: 0.0815 - val_out_6_loss: 0.0702 - val_out_7_loss: 0.1637 - val_out_8_loss: 0.1056 - val_out_9_loss: 0.1379 - val_final_output_loss: 4.6479 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 103/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.6155 - out_0_loss: 0.3940 - out_1_loss: 0.3944 - out_2_loss: 0.4127 - out_3_loss: 0.4461 - out_4_loss: 0.3685 - out_5_loss: 0.3791 - out_6_loss: 0.3461 - out_7_loss: 0.3029 - out_8_loss: 0.4442 - out_9_loss: 0.3475 - final_output_loss: 5.7800 - out_0_acc: 5.8676e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1186 - val_loss: 5.7290 - val_out_0_loss: 0.1045 - val_out_1_loss: 0.0744 - val_out_2_loss: 0.0983 - val_out_3_loss: 0.1208 - val_out_4_loss: 0.1142 - val_out_5_loss: 0.0746 - val_out_6_loss: 0.1038 - val_out_7_loss: 0.1438 - val_out_8_loss: 0.1035 - val_out_9_loss: 0.1312 - val_final_output_loss: 4.6599 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 104/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.5089 - out_0_loss: 0.3906 - out_1_loss: 0.3871 - out_2_loss: 0.4131 - out_3_loss: 0.4444 - out_4_loss: 0.3668 - out_5_loss: 0.3740 - out_6_loss: 0.3420 - out_7_loss: 0.3008 - out_8_loss: 0.4448 - out_9_loss: 0.3461 - final_output_loss: 5.6991 - out_0_acc: 8.0013e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1167 - val_loss: 5.6722 - val_out_0_loss: 0.1078 - val_out_1_loss: 0.0974 - val_out_2_loss: 0.1146 - val_out_3_loss: 0.1154 - val_out_4_loss: 0.1099 - val_out_5_loss: 0.0688 - val_out_6_loss: 0.0962 - val_out_7_loss: 0.1323 - val_out_8_loss: 0.0922 - val_out_9_loss: 0.1106 - val_final_output_loss: 4.6271 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 105/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.4549 - out_0_loss: 0.3870 - out_1_loss: 0.3828 - out_2_loss: 0.4065 - out_3_loss: 0.4485 - out_4_loss: 0.3614 - out_5_loss: 0.3725 - out_6_loss: 0.3367 - out_7_loss: 0.3024 - out_8_loss: 0.4419 - out_9_loss: 0.3412 - final_output_loss: 5.6740 - out_0_acc: 6.4010e-05 - out_1_acc: 5.8676e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1147 - val_loss: 5.6659 - val_out_0_loss: 0.1010 - val_out_1_loss: 0.0827 - val_out_2_loss: 0.0925 - val_out_3_loss: 0.1205 - val_out_4_loss: 0.0994 - val_out_5_loss: 0.0590 - val_out_6_loss: 0.1128 - val_out_7_loss: 0.1491 - val_out_8_loss: 0.1047 - val_out_9_loss: 0.1165 - val_final_output_loss: 4.6278 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 106/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.4116 - out_0_loss: 0.3855 - out_1_loss: 0.3762 - out_2_loss: 0.4105 - out_3_loss: 0.4410 - out_4_loss: 0.3635 - out_5_loss: 0.3644 - out_6_loss: 0.3311 - out_7_loss: 0.2976 - out_8_loss: 0.4326 - out_9_loss: 0.3391 - final_output_loss: 5.6702 - out_0_acc: 6.4010e-05 - out_1_acc: 5.8676e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1176 - val_loss: 5.5873 - val_out_0_loss: 0.1043 - val_out_1_loss: 0.0641 - val_out_2_loss: 0.0951 - val_out_3_loss: 0.1187 - val_out_4_loss: 0.1015 - val_out_5_loss: 0.0609 - val_out_6_loss: 0.0927 - val_out_7_loss: 0.1477 - val_out_8_loss: 0.0996 - val_out_9_loss: 0.1046 - val_final_output_loss: 4.5983 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 107/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.3117 - out_0_loss: 0.3793 - out_1_loss: 0.3786 - out_2_loss: 0.4064 - out_3_loss: 0.4365 - out_4_loss: 0.3562 - out_5_loss: 0.3659 - out_6_loss: 0.3308 - out_7_loss: 0.2951 - out_8_loss: 0.4283 - out_9_loss: 0.3384 - final_output_loss: 5.5963 - out_0_acc: 7.4679e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1219 - val_loss: 5.6291 - val_out_0_loss: 0.1028 - val_out_1_loss: 0.0594 - val_out_2_loss: 0.1001 - val_out_3_loss: 0.1283 - val_out_4_loss: 0.1205 - val_out_5_loss: 0.0674 - val_out_6_loss: 0.0958 - val_out_7_loss: 0.1376 - val_out_8_loss: 0.0952 - val_out_9_loss: 0.1071 - val_final_output_loss: 4.6149 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 108/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.3643 - out_0_loss: 0.3761 - out_1_loss: 0.3730 - out_2_loss: 0.3995 - out_3_loss: 0.4305 - out_4_loss: 0.3555 - out_5_loss: 0.3611 - out_6_loss: 0.3289 - out_7_loss: 0.2943 - out_8_loss: 0.4250 - out_9_loss: 0.3330 - final_output_loss: 5.6875 - out_0_acc: 5.8676e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1114 - val_loss: 5.0200 - val_out_0_loss: 0.0798 - val_out_1_loss: 0.0636 - val_out_2_loss: 0.0790 - val_out_3_loss: 0.1248 - val_out_4_loss: 0.0964 - val_out_5_loss: 0.0575 - val_out_6_loss: 0.0776 - val_out_7_loss: 0.1554 - val_out_8_loss: 0.0976 - val_out_9_loss: 0.0936 - val_final_output_loss: 4.0947 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 109/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.3953 - out_0_loss: 0.3740 - out_1_loss: 0.3676 - out_2_loss: 0.3942 - out_3_loss: 0.4310 - out_4_loss: 0.3546 - out_5_loss: 0.3608 - out_6_loss: 0.3252 - out_7_loss: 0.2926 - out_8_loss: 0.4199 - out_9_loss: 0.3273 - final_output_loss: 5.7481 - out_0_acc: 7.4679e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1186 - val_loss: 5.7736 - val_out_0_loss: 0.1009 - val_out_1_loss: 0.0759 - val_out_2_loss: 0.0996 - val_out_3_loss: 0.1388 - val_out_4_loss: 0.1394 - val_out_5_loss: 0.0845 - val_out_6_loss: 0.1072 - val_out_7_loss: 0.1607 - val_out_8_loss: 0.1166 - val_out_9_loss: 0.1343 - val_final_output_loss: 4.6157 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 110/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.0695 - out_0_loss: 0.3696 - out_1_loss: 0.3627 - out_2_loss: 0.3876 - out_3_loss: 0.4292 - out_4_loss: 0.3452 - out_5_loss: 0.3567 - out_6_loss: 0.3235 - out_7_loss: 0.2857 - out_8_loss: 0.4111 - out_9_loss: 0.3274 - final_output_loss: 5.4706 - out_0_acc: 6.9344e-05 - out_1_acc: 4.8008e-05 - out_2_acc: 5.3342e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 5.8676e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1157 - val_loss: 5.0853 - val_out_0_loss: 0.0999 - val_out_1_loss: 0.0620 - val_out_2_loss: 0.0808 - val_out_3_loss: 0.1300 - val_out_4_loss: 0.0980 - val_out_5_loss: 0.0775 - val_out_6_loss: 0.0895 - val_out_7_loss: 0.1336 - val_out_8_loss: 0.1026 - val_out_9_loss: 0.1191 - val_final_output_loss: 4.0923 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 111/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.2855 - out_0_loss: 0.3671 - out_1_loss: 0.3639 - out_2_loss: 0.3902 - out_3_loss: 0.4224 - out_4_loss: 0.3412 - out_5_loss: 0.3559 - out_6_loss: 0.3153 - out_7_loss: 0.2871 - out_8_loss: 0.4099 - out_9_loss: 0.3244 - final_output_loss: 5.7081 - out_0_acc: 7.4679e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 4.8008e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1210 - val_loss: 5.2627 - val_out_0_loss: 0.0952 - val_out_1_loss: 0.0802 - val_out_2_loss: 0.1010 - val_out_3_loss: 0.1056 - val_out_4_loss: 0.1125 - val_out_5_loss: 0.0722 - val_out_6_loss: 0.1180 - val_out_7_loss: 0.1643 - val_out_8_loss: 0.1159 - val_out_9_loss: 0.1334 - val_final_output_loss: 4.1643 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 112/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.0961 - out_0_loss: 0.3606 - out_1_loss: 0.3607 - out_2_loss: 0.3820 - out_3_loss: 0.4231 - out_4_loss: 0.3439 - out_5_loss: 0.3515 - out_6_loss: 0.3147 - out_7_loss: 0.2840 - out_8_loss: 0.4034 - out_9_loss: 0.3209 - final_output_loss: 5.5514 - out_0_acc: 8.0013e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1104 - val_loss: 5.1371 - val_out_0_loss: 0.1102 - val_out_1_loss: 0.0709 - val_out_2_loss: 0.0897 - val_out_3_loss: 0.1202 - val_out_4_loss: 0.1099 - val_out_5_loss: 0.0727 - val_out_6_loss: 0.0996 - val_out_7_loss: 0.1506 - val_out_8_loss: 0.1153 - val_out_9_loss: 0.1200 - val_final_output_loss: 4.0780 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 113/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.3134 - out_0_loss: 0.3605 - out_1_loss: 0.3549 - out_2_loss: 0.3815 - out_3_loss: 0.4176 - out_4_loss: 0.3372 - out_5_loss: 0.3449 - out_6_loss: 0.3120 - out_7_loss: 0.2874 - out_8_loss: 0.4057 - out_9_loss: 0.3209 - final_output_loss: 5.7908 - out_0_acc: 7.4679e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1171 - val_loss: 5.0861 - val_out_0_loss: 0.0987 - val_out_1_loss: 0.0700 - val_out_2_loss: 0.0953 - val_out_3_loss: 0.1335 - val_out_4_loss: 0.0967 - val_out_5_loss: 0.0688 - val_out_6_loss: 0.0871 - val_out_7_loss: 0.1375 - val_out_8_loss: 0.0919 - val_out_9_loss: 0.1137 - val_final_output_loss: 4.0929 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 114/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.3829 - out_0_loss: 0.3572 - out_1_loss: 0.3531 - out_2_loss: 0.3763 - out_3_loss: 0.4140 - out_4_loss: 0.3395 - out_5_loss: 0.3428 - out_6_loss: 0.3118 - out_7_loss: 0.2814 - out_8_loss: 0.3991 - out_9_loss: 0.3218 - final_output_loss: 5.8861 - out_0_acc: 6.9344e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1186 - val_loss: 5.0081 - val_out_0_loss: 0.0763 - val_out_1_loss: 0.0566 - val_out_2_loss: 0.0754 - val_out_3_loss: 0.1131 - val_out_4_loss: 0.0799 - val_out_5_loss: 0.0494 - val_out_6_loss: 0.0932 - val_out_7_loss: 0.1522 - val_out_8_loss: 0.1197 - val_out_9_loss: 0.1232 - val_final_output_loss: 4.0690 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 115/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.3360 - out_0_loss: 0.3526 - out_1_loss: 0.3478 - out_2_loss: 0.3746 - out_3_loss: 0.4107 - out_4_loss: 0.3327 - out_5_loss: 0.3410 - out_6_loss: 0.3076 - out_7_loss: 0.2789 - out_8_loss: 0.3932 - out_9_loss: 0.3168 - final_output_loss: 5.8800 - out_0_acc: 7.4679e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 5.3342e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1104 - val_loss: 5.1189 - val_out_0_loss: 0.0839 - val_out_1_loss: 0.0758 - val_out_2_loss: 0.0966 - val_out_3_loss: 0.1414 - val_out_4_loss: 0.1200 - val_out_5_loss: 0.0983 - val_out_6_loss: 0.0935 - val_out_7_loss: 0.1558 - val_out_8_loss: 0.1009 - val_out_9_loss: 0.1005 - val_final_output_loss: 4.0524 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 116/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.0859 - out_0_loss: 0.3499 - out_1_loss: 0.3468 - out_2_loss: 0.3741 - out_3_loss: 0.4035 - out_4_loss: 0.3329 - out_5_loss: 0.3393 - out_6_loss: 0.3035 - out_7_loss: 0.2772 - out_8_loss: 0.3893 - out_9_loss: 0.3132 - final_output_loss: 5.6562 - out_0_acc: 5.3342e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1147 - val_loss: 5.0395 - val_out_0_loss: 0.0977 - val_out_1_loss: 0.0703 - val_out_2_loss: 0.0972 - val_out_3_loss: 0.1308 - val_out_4_loss: 0.1059 - val_out_5_loss: 0.0473 - val_out_6_loss: 0.0827 - val_out_7_loss: 0.1379 - val_out_8_loss: 0.1091 - val_out_9_loss: 0.1176 - val_final_output_loss: 4.0429 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 117/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.0322 - out_0_loss: 0.3494 - out_1_loss: 0.3450 - out_2_loss: 0.3702 - out_3_loss: 0.4069 - out_4_loss: 0.3324 - out_5_loss: 0.3391 - out_6_loss: 0.2987 - out_7_loss: 0.2748 - out_8_loss: 0.3829 - out_9_loss: 0.3110 - final_output_loss: 5.6217 - out_0_acc: 6.9344e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 5.3342e-05 - final_output_acc: 0.1191 - val_loss: 5.0742 - val_out_0_loss: 0.0909 - val_out_1_loss: 0.0792 - val_out_2_loss: 0.0937 - val_out_3_loss: 0.1247 - val_out_4_loss: 0.1035 - val_out_5_loss: 0.0806 - val_out_6_loss: 0.1055 - val_out_7_loss: 0.1517 - val_out_8_loss: 0.1219 - val_out_9_loss: 0.1096 - val_final_output_loss: 4.0130 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 118/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.9058 - out_0_loss: 0.3447 - out_1_loss: 0.3425 - out_2_loss: 0.3685 - out_3_loss: 0.4038 - out_4_loss: 0.3267 - out_5_loss: 0.3324 - out_6_loss: 0.2975 - out_7_loss: 0.2752 - out_8_loss: 0.3810 - out_9_loss: 0.3077 - final_output_loss: 5.5259 - out_0_acc: 8.0013e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 8.0013e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1133 - val_loss: 4.9762 - val_out_0_loss: 0.0986 - val_out_1_loss: 0.0710 - val_out_2_loss: 0.0986 - val_out_3_loss: 0.1154 - val_out_4_loss: 0.0988 - val_out_5_loss: 0.0706 - val_out_6_loss: 0.0888 - val_out_7_loss: 0.1335 - val_out_8_loss: 0.1028 - val_out_9_loss: 0.0989 - val_final_output_loss: 3.9993 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 119/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.0900 - out_0_loss: 0.3421 - out_1_loss: 0.3412 - out_2_loss: 0.3577 - out_3_loss: 0.3996 - out_4_loss: 0.3258 - out_5_loss: 0.3315 - out_6_loss: 0.2952 - out_7_loss: 0.2773 - out_8_loss: 0.3744 - out_9_loss: 0.3078 - final_output_loss: 5.7373 - out_0_acc: 6.9344e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 5.8676e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1114 - val_loss: 5.0517 - val_out_0_loss: 0.0993 - val_out_1_loss: 0.0732 - val_out_2_loss: 0.0726 - val_out_3_loss: 0.1139 - val_out_4_loss: 0.1000 - val_out_5_loss: 0.0680 - val_out_6_loss: 0.1102 - val_out_7_loss: 0.1729 - val_out_8_loss: 0.1028 - val_out_9_loss: 0.1198 - val_final_output_loss: 4.0190 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 120/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 9.0723 - out_0_loss: 0.3368 - out_1_loss: 0.3377 - out_2_loss: 0.3593 - out_3_loss: 0.3940 - out_4_loss: 0.3253 - out_5_loss: 0.3309 - out_6_loss: 0.2918 - out_7_loss: 0.2740 - out_8_loss: 0.3742 - out_9_loss: 0.3076 - final_output_loss: 5.7407 - out_0_acc: 6.4010e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 8.0013e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1258 - val_loss: 4.8975 - val_out_0_loss: 0.0991 - val_out_1_loss: 0.0594 - val_out_2_loss: 0.0792 - val_out_3_loss: 0.0991 - val_out_4_loss: 0.0762 - val_out_5_loss: 0.0580 - val_out_6_loss: 0.0908 - val_out_7_loss: 0.1409 - val_out_8_loss: 0.1007 - val_out_9_loss: 0.1092 - val_final_output_loss: 3.9850 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 121/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.8019 - out_0_loss: 0.3349 - out_1_loss: 0.3336 - out_2_loss: 0.3534 - out_3_loss: 0.3942 - out_4_loss: 0.3175 - out_5_loss: 0.3291 - out_6_loss: 0.2948 - out_7_loss: 0.2737 - out_8_loss: 0.3707 - out_9_loss: 0.3064 - final_output_loss: 5.4935 - out_0_acc: 6.9344e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1181 - val_loss: 5.1397 - val_out_0_loss: 0.1120 - val_out_1_loss: 0.0778 - val_out_2_loss: 0.0997 - val_out_3_loss: 0.1311 - val_out_4_loss: 0.1067 - val_out_5_loss: 0.0868 - val_out_6_loss: 0.1181 - val_out_7_loss: 0.1598 - val_out_8_loss: 0.1160 - val_out_9_loss: 0.1299 - val_final_output_loss: 4.0019 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 122/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.8731 - out_0_loss: 0.3365 - out_1_loss: 0.3307 - out_2_loss: 0.3517 - out_3_loss: 0.3897 - out_4_loss: 0.3190 - out_5_loss: 0.3217 - out_6_loss: 0.2880 - out_7_loss: 0.2736 - out_8_loss: 0.3621 - out_9_loss: 0.3037 - final_output_loss: 5.5962 - out_0_acc: 5.8676e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1176 - val_loss: 4.9616 - val_out_0_loss: 0.1008 - val_out_1_loss: 0.0625 - val_out_2_loss: 0.0744 - val_out_3_loss: 0.1050 - val_out_4_loss: 0.1016 - val_out_5_loss: 0.0879 - val_out_6_loss: 0.0951 - val_out_7_loss: 0.1409 - val_out_8_loss: 0.0931 - val_out_9_loss: 0.1165 - val_final_output_loss: 3.9839 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 123/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.7497 - out_0_loss: 0.3303 - out_1_loss: 0.3263 - out_2_loss: 0.3510 - out_3_loss: 0.3868 - out_4_loss: 0.3139 - out_5_loss: 0.3196 - out_6_loss: 0.2870 - out_7_loss: 0.2690 - out_8_loss: 0.3600 - out_9_loss: 0.2985 - final_output_loss: 5.5072 - out_0_acc: 6.4010e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1263 - val_loss: 4.9844 - val_out_0_loss: 0.1033 - val_out_1_loss: 0.0712 - val_out_2_loss: 0.0981 - val_out_3_loss: 0.1237 - val_out_4_loss: 0.0985 - val_out_5_loss: 0.0695 - val_out_6_loss: 0.1041 - val_out_7_loss: 0.1648 - val_out_8_loss: 0.1050 - val_out_9_loss: 0.1072 - val_final_output_loss: 3.9391 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 124/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.6677 - out_0_loss: 0.3268 - out_1_loss: 0.3268 - out_2_loss: 0.3462 - out_3_loss: 0.3873 - out_4_loss: 0.3146 - out_5_loss: 0.3182 - out_6_loss: 0.2832 - out_7_loss: 0.2653 - out_8_loss: 0.3585 - out_9_loss: 0.2966 - final_output_loss: 5.4443 - out_0_acc: 7.4679e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1095 - val_loss: 4.9481 - val_out_0_loss: 0.1036 - val_out_1_loss: 0.0773 - val_out_2_loss: 0.0767 - val_out_3_loss: 0.0918 - val_out_4_loss: 0.1108 - val_out_5_loss: 0.0689 - val_out_6_loss: 0.1003 - val_out_7_loss: 0.1435 - val_out_8_loss: 0.1093 - val_out_9_loss: 0.1168 - val_final_output_loss: 3.9490 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 125/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.4950 - out_0_loss: 0.3277 - out_1_loss: 0.3237 - out_2_loss: 0.3406 - out_3_loss: 0.3809 - out_4_loss: 0.3116 - out_5_loss: 0.3183 - out_6_loss: 0.2781 - out_7_loss: 0.2658 - out_8_loss: 0.3591 - out_9_loss: 0.2937 - final_output_loss: 5.2955 - out_0_acc: 6.9344e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1162 - val_loss: 4.9578 - val_out_0_loss: 0.0917 - val_out_1_loss: 0.0586 - val_out_2_loss: 0.0878 - val_out_3_loss: 0.1199 - val_out_4_loss: 0.1007 - val_out_5_loss: 0.0853 - val_out_6_loss: 0.0894 - val_out_7_loss: 0.1449 - val_out_8_loss: 0.1093 - val_out_9_loss: 0.1183 - val_final_output_loss: 3.9521 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 126/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.4608 - out_0_loss: 0.3229 - out_1_loss: 0.3195 - out_2_loss: 0.3439 - out_3_loss: 0.3758 - out_4_loss: 0.3055 - out_5_loss: 0.3131 - out_6_loss: 0.2804 - out_7_loss: 0.2666 - out_8_loss: 0.3488 - out_9_loss: 0.2912 - final_output_loss: 5.2932 - out_0_acc: 8.0013e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1210 - val_loss: 4.9259 - val_out_0_loss: 0.0742 - val_out_1_loss: 0.0713 - val_out_2_loss: 0.0932 - val_out_3_loss: 0.1152 - val_out_4_loss: 0.0964 - val_out_5_loss: 0.0865 - val_out_6_loss: 0.0935 - val_out_7_loss: 0.1505 - val_out_8_loss: 0.1008 - val_out_9_loss: 0.1049 - val_final_output_loss: 3.9393 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 127/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.4566 - out_0_loss: 0.3234 - out_1_loss: 0.3153 - out_2_loss: 0.3344 - out_3_loss: 0.3763 - out_4_loss: 0.3087 - out_5_loss: 0.3123 - out_6_loss: 0.2758 - out_7_loss: 0.2658 - out_8_loss: 0.3521 - out_9_loss: 0.2909 - final_output_loss: 5.3016 - out_0_acc: 6.9344e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1239 - val_loss: 4.5131 - val_out_0_loss: 0.0976 - val_out_1_loss: 0.0688 - val_out_2_loss: 0.0948 - val_out_3_loss: 0.1098 - val_out_4_loss: 0.1008 - val_out_5_loss: 0.0854 - val_out_6_loss: 0.1088 - val_out_7_loss: 0.1545 - val_out_8_loss: 0.1133 - val_out_9_loss: 0.1082 - val_final_output_loss: 3.4712 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 128/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.2462 - out_0_loss: 0.3156 - out_1_loss: 0.3156 - out_2_loss: 0.3324 - out_3_loss: 0.3727 - out_4_loss: 0.3050 - out_5_loss: 0.3069 - out_6_loss: 0.2727 - out_7_loss: 0.2625 - out_8_loss: 0.3445 - out_9_loss: 0.2878 - final_output_loss: 5.1304 - out_0_acc: 7.4679e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 5.3342e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1133 - val_loss: 3.9241 - val_out_0_loss: 0.0952 - val_out_1_loss: 0.0914 - val_out_2_loss: 0.0794 - val_out_3_loss: 0.1186 - val_out_4_loss: 0.1026 - val_out_5_loss: 0.0702 - val_out_6_loss: 0.1060 - val_out_7_loss: 0.1473 - val_out_8_loss: 0.1097 - val_out_9_loss: 0.1086 - val_final_output_loss: 2.8951 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 129/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.2740 - out_0_loss: 0.3151 - out_1_loss: 0.3089 - out_2_loss: 0.3309 - out_3_loss: 0.3777 - out_4_loss: 0.3028 - out_5_loss: 0.3057 - out_6_loss: 0.2736 - out_7_loss: 0.2630 - out_8_loss: 0.3417 - out_9_loss: 0.2878 - final_output_loss: 5.1668 - out_0_acc: 8.0013e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1080 - val_loss: 3.8039 - val_out_0_loss: 0.1033 - val_out_1_loss: 0.0774 - val_out_2_loss: 0.0920 - val_out_3_loss: 0.1280 - val_out_4_loss: 0.0961 - val_out_5_loss: 0.0681 - val_out_6_loss: 0.0825 - val_out_7_loss: 0.1274 - val_out_8_loss: 0.1151 - val_out_9_loss: 0.1045 - val_final_output_loss: 2.8095 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 130/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.2604 - out_0_loss: 0.3147 - out_1_loss: 0.3143 - out_2_loss: 0.3347 - out_3_loss: 0.3743 - out_4_loss: 0.3037 - out_5_loss: 0.3061 - out_6_loss: 0.2691 - out_7_loss: 0.2585 - out_8_loss: 0.3418 - out_9_loss: 0.2868 - final_output_loss: 5.1563 - out_0_acc: 7.4679e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 8.0013e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1210 - val_loss: 3.8000 - val_out_0_loss: 0.1071 - val_out_1_loss: 0.0793 - val_out_2_loss: 0.1028 - val_out_3_loss: 0.1179 - val_out_4_loss: 0.0905 - val_out_5_loss: 0.0593 - val_out_6_loss: 0.0953 - val_out_7_loss: 0.1324 - val_out_8_loss: 0.1117 - val_out_9_loss: 0.1186 - val_final_output_loss: 2.7851 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 131/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.2333 - out_0_loss: 0.3141 - out_1_loss: 0.3069 - out_2_loss: 0.3258 - out_3_loss: 0.3696 - out_4_loss: 0.3002 - out_5_loss: 0.3052 - out_6_loss: 0.2670 - out_7_loss: 0.2601 - out_8_loss: 0.3340 - out_9_loss: 0.2833 - final_output_loss: 5.1672 - out_0_acc: 8.0013e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1311 - val_loss: 3.7859 - val_out_0_loss: 0.1134 - val_out_1_loss: 0.0684 - val_out_2_loss: 0.0814 - val_out_3_loss: 0.1125 - val_out_4_loss: 0.1048 - val_out_5_loss: 0.0786 - val_out_6_loss: 0.0928 - val_out_7_loss: 0.1554 - val_out_8_loss: 0.1101 - val_out_9_loss: 0.1088 - val_final_output_loss: 2.7597 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 132/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 8.0519 - out_0_loss: 0.3121 - out_1_loss: 0.3038 - out_2_loss: 0.3260 - out_3_loss: 0.3610 - out_4_loss: 0.2982 - out_5_loss: 0.3008 - out_6_loss: 0.2673 - out_7_loss: 0.2541 - out_8_loss: 0.3291 - out_9_loss: 0.2838 - final_output_loss: 5.0155 - out_0_acc: 6.9344e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.4010e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1085 - val_loss: 3.6692 - val_out_0_loss: 0.0900 - val_out_1_loss: 0.0557 - val_out_2_loss: 0.0698 - val_out_3_loss: 0.0931 - val_out_4_loss: 0.0899 - val_out_5_loss: 0.0666 - val_out_6_loss: 0.1069 - val_out_7_loss: 0.1522 - val_out_8_loss: 0.1127 - val_out_9_loss: 0.1045 - val_final_output_loss: 2.7278 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 133/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 7.9637 - out_0_loss: 0.3074 - out_1_loss: 0.3018 - out_2_loss: 0.3227 - out_3_loss: 0.3611 - out_4_loss: 0.2938 - out_5_loss: 0.2998 - out_6_loss: 0.2642 - out_7_loss: 0.2594 - out_8_loss: 0.3279 - out_9_loss: 0.2829 - final_output_loss: 4.9425 - out_0_acc: 6.9344e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 6.4010e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1229 - val_loss: 3.6933 - val_out_0_loss: 0.0976 - val_out_1_loss: 0.0721 - val_out_2_loss: 0.0823 - val_out_3_loss: 0.1294 - val_out_4_loss: 0.1039 - val_out_5_loss: 0.0752 - val_out_6_loss: 0.1109 - val_out_7_loss: 0.1297 - val_out_8_loss: 0.0948 - val_out_9_loss: 0.0827 - val_final_output_loss: 2.7146 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 134/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 7.8693 - out_0_loss: 0.3055 - out_1_loss: 0.2977 - out_2_loss: 0.3192 - out_3_loss: 0.3569 - out_4_loss: 0.2937 - out_5_loss: 0.2970 - out_6_loss: 0.2621 - out_7_loss: 0.2599 - out_8_loss: 0.3256 - out_9_loss: 0.2797 - final_output_loss: 4.8720 - out_0_acc: 8.0013e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1191 - val_loss: 3.7460 - val_out_0_loss: 0.0975 - val_out_1_loss: 0.0792 - val_out_2_loss: 0.0810 - val_out_3_loss: 0.1097 - val_out_4_loss: 0.1112 - val_out_5_loss: 0.0802 - val_out_6_loss: 0.1044 - val_out_7_loss: 0.1608 - val_out_8_loss: 0.1129 - val_out_9_loss: 0.1097 - val_final_output_loss: 2.6995 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 135/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 7.8226 - out_0_loss: 0.3037 - out_1_loss: 0.2986 - out_2_loss: 0.3167 - out_3_loss: 0.3592 - out_4_loss: 0.2902 - out_5_loss: 0.2917 - out_6_loss: 0.2577 - out_7_loss: 0.2550 - out_8_loss: 0.3221 - out_9_loss: 0.2770 - final_output_loss: 4.8509 - out_0_acc: 6.4010e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1224 - val_loss: 3.1242 - val_out_0_loss: 0.0854 - val_out_1_loss: 0.0602 - val_out_2_loss: 0.0810 - val_out_3_loss: 0.1027 - val_out_4_loss: 0.1031 - val_out_5_loss: 0.0686 - val_out_6_loss: 0.0955 - val_out_7_loss: 0.1318 - val_out_8_loss: 0.1040 - val_out_9_loss: 0.1038 - val_final_output_loss: 2.1880 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 136/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 7.6119 - out_0_loss: 0.3005 - out_1_loss: 0.2979 - out_2_loss: 0.3162 - out_3_loss: 0.3567 - out_4_loss: 0.2896 - out_5_loss: 0.2908 - out_6_loss: 0.2577 - out_7_loss: 0.2545 - out_8_loss: 0.3208 - out_9_loss: 0.2766 - final_output_loss: 4.6506 - out_0_acc: 8.0013e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1138 - val_loss: 3.1106 - val_out_0_loss: 0.1016 - val_out_1_loss: 0.0663 - val_out_2_loss: 0.0828 - val_out_3_loss: 0.1028 - val_out_4_loss: 0.1041 - val_out_5_loss: 0.0668 - val_out_6_loss: 0.0961 - val_out_7_loss: 0.1512 - val_out_8_loss: 0.0971 - val_out_9_loss: 0.0939 - val_final_output_loss: 2.1479 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0909\n",
            "Epoch 137/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 7.5836 - out_0_loss: 0.3007 - out_1_loss: 0.2934 - out_2_loss: 0.3125 - out_3_loss: 0.3555 - out_4_loss: 0.2853 - out_5_loss: 0.2865 - out_6_loss: 0.2566 - out_7_loss: 0.2530 - out_8_loss: 0.3158 - out_9_loss: 0.2717 - final_output_loss: 4.6525 - out_0_acc: 5.8676e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 5.3342e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 6.4010e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1229 - val_loss: 3.0069 - val_out_0_loss: 0.0870 - val_out_1_loss: 0.0748 - val_out_2_loss: 0.0740 - val_out_3_loss: 0.0974 - val_out_4_loss: 0.1029 - val_out_5_loss: 0.0694 - val_out_6_loss: 0.0929 - val_out_7_loss: 0.1415 - val_out_8_loss: 0.0822 - val_out_9_loss: 0.0940 - val_final_output_loss: 2.0907 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0909\n",
            "Epoch 138/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 7.4000 - out_0_loss: 0.2989 - out_1_loss: 0.2933 - out_2_loss: 0.3149 - out_3_loss: 0.3550 - out_4_loss: 0.2824 - out_5_loss: 0.2911 - out_6_loss: 0.2561 - out_7_loss: 0.2510 - out_8_loss: 0.3140 - out_9_loss: 0.2749 - final_output_loss: 4.4682 - out_0_acc: 7.4679e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1258 - val_loss: 3.0495 - val_out_0_loss: 0.1019 - val_out_1_loss: 0.0523 - val_out_2_loss: 0.0679 - val_out_3_loss: 0.1022 - val_out_4_loss: 0.0975 - val_out_5_loss: 0.0981 - val_out_6_loss: 0.0910 - val_out_7_loss: 0.1513 - val_out_8_loss: 0.1028 - val_out_9_loss: 0.1074 - val_final_output_loss: 2.0769 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.0909\n",
            "Epoch 139/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 7.2566 - out_0_loss: 0.2958 - out_1_loss: 0.2901 - out_2_loss: 0.3095 - out_3_loss: 0.3454 - out_4_loss: 0.2837 - out_5_loss: 0.2848 - out_6_loss: 0.2537 - out_7_loss: 0.2489 - out_8_loss: 0.3091 - out_9_loss: 0.2720 - final_output_loss: 4.3636 - out_0_acc: 6.9344e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1229 - val_loss: 3.0405 - val_out_0_loss: 0.0969 - val_out_1_loss: 0.0838 - val_out_2_loss: 0.0930 - val_out_3_loss: 0.1158 - val_out_4_loss: 0.1056 - val_out_5_loss: 0.0760 - val_out_6_loss: 0.0758 - val_out_7_loss: 0.1357 - val_out_8_loss: 0.0937 - val_out_9_loss: 0.1131 - val_final_output_loss: 2.0512 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 140/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 7.3513 - out_0_loss: 0.2957 - out_1_loss: 0.2881 - out_2_loss: 0.3045 - out_3_loss: 0.3441 - out_4_loss: 0.2783 - out_5_loss: 0.2853 - out_6_loss: 0.2506 - out_7_loss: 0.2488 - out_8_loss: 0.3081 - out_9_loss: 0.2697 - final_output_loss: 4.4782 - out_0_acc: 7.4679e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1267 - val_loss: 2.9125 - val_out_0_loss: 0.0857 - val_out_1_loss: 0.0653 - val_out_2_loss: 0.0840 - val_out_3_loss: 0.1009 - val_out_4_loss: 0.1008 - val_out_5_loss: 0.0505 - val_out_6_loss: 0.0804 - val_out_7_loss: 0.1343 - val_out_8_loss: 0.0984 - val_out_9_loss: 0.0931 - val_final_output_loss: 2.0191 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 141/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 7.2084 - out_0_loss: 0.2933 - out_1_loss: 0.2827 - out_2_loss: 0.3057 - out_3_loss: 0.3393 - out_4_loss: 0.2811 - out_5_loss: 0.2842 - out_6_loss: 0.2507 - out_7_loss: 0.2490 - out_8_loss: 0.3047 - out_9_loss: 0.2713 - final_output_loss: 4.3462 - out_0_acc: 6.9344e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 8.0013e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1210 - val_loss: 3.0756 - val_out_0_loss: 0.1042 - val_out_1_loss: 0.0751 - val_out_2_loss: 0.0870 - val_out_3_loss: 0.1259 - val_out_4_loss: 0.1047 - val_out_5_loss: 0.0716 - val_out_6_loss: 0.1040 - val_out_7_loss: 0.1585 - val_out_8_loss: 0.1151 - val_out_9_loss: 0.1197 - val_final_output_loss: 2.0098 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 142/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 7.0173 - out_0_loss: 0.2898 - out_1_loss: 0.2870 - out_2_loss: 0.3037 - out_3_loss: 0.3457 - out_4_loss: 0.2789 - out_5_loss: 0.2839 - out_6_loss: 0.2482 - out_7_loss: 0.2468 - out_8_loss: 0.3034 - out_9_loss: 0.2680 - final_output_loss: 4.1619 - out_0_acc: 7.4679e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1195 - val_loss: 2.8675 - val_out_0_loss: 0.0873 - val_out_1_loss: 0.0482 - val_out_2_loss: 0.0754 - val_out_3_loss: 0.0950 - val_out_4_loss: 0.0939 - val_out_5_loss: 0.0581 - val_out_6_loss: 0.0791 - val_out_7_loss: 0.1390 - val_out_8_loss: 0.0910 - val_out_9_loss: 0.0932 - val_final_output_loss: 2.0073 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 143/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.8239 - out_0_loss: 0.2885 - out_1_loss: 0.2800 - out_2_loss: 0.2996 - out_3_loss: 0.3336 - out_4_loss: 0.2746 - out_5_loss: 0.2773 - out_6_loss: 0.2492 - out_7_loss: 0.2464 - out_8_loss: 0.2987 - out_9_loss: 0.2664 - final_output_loss: 4.0095 - out_0_acc: 7.4679e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1215 - val_loss: 3.0040 - val_out_0_loss: 0.0829 - val_out_1_loss: 0.0607 - val_out_2_loss: 0.0912 - val_out_3_loss: 0.1052 - val_out_4_loss: 0.0945 - val_out_5_loss: 0.0843 - val_out_6_loss: 0.0973 - val_out_7_loss: 0.1338 - val_out_8_loss: 0.1230 - val_out_9_loss: 0.1204 - val_final_output_loss: 2.0107 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 144/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 7.0422 - out_0_loss: 0.2822 - out_1_loss: 0.2803 - out_2_loss: 0.2966 - out_3_loss: 0.3363 - out_4_loss: 0.2763 - out_5_loss: 0.2777 - out_6_loss: 0.2499 - out_7_loss: 0.2457 - out_8_loss: 0.2983 - out_9_loss: 0.2649 - final_output_loss: 4.2339 - out_0_acc: 6.9344e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 8.0013e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.4010e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1315 - val_loss: 2.8972 - val_out_0_loss: 0.0861 - val_out_1_loss: 0.0634 - val_out_2_loss: 0.0886 - val_out_3_loss: 0.1098 - val_out_4_loss: 0.0951 - val_out_5_loss: 0.0708 - val_out_6_loss: 0.0875 - val_out_7_loss: 0.1217 - val_out_8_loss: 0.0766 - val_out_9_loss: 0.0890 - val_final_output_loss: 2.0086 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 145/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.9316 - out_0_loss: 0.2821 - out_1_loss: 0.2752 - out_2_loss: 0.2956 - out_3_loss: 0.3322 - out_4_loss: 0.2740 - out_5_loss: 0.2745 - out_6_loss: 0.2467 - out_7_loss: 0.2465 - out_8_loss: 0.2971 - out_9_loss: 0.2653 - final_output_loss: 4.1423 - out_0_acc: 7.4679e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 8.0013e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1195 - val_loss: 2.8718 - val_out_0_loss: 0.0928 - val_out_1_loss: 0.0772 - val_out_2_loss: 0.0818 - val_out_3_loss: 0.1018 - val_out_4_loss: 0.0919 - val_out_5_loss: 0.0665 - val_out_6_loss: 0.0729 - val_out_7_loss: 0.1238 - val_out_8_loss: 0.0951 - val_out_9_loss: 0.0823 - val_final_output_loss: 1.9857 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 146/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.8075 - out_0_loss: 0.2803 - out_1_loss: 0.2793 - out_2_loss: 0.2931 - out_3_loss: 0.3341 - out_4_loss: 0.2734 - out_5_loss: 0.2731 - out_6_loss: 0.2423 - out_7_loss: 0.2446 - out_8_loss: 0.2923 - out_9_loss: 0.2599 - final_output_loss: 4.0349 - out_0_acc: 7.4679e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1215 - val_loss: 3.0112 - val_out_0_loss: 0.1069 - val_out_1_loss: 0.0843 - val_out_2_loss: 0.0876 - val_out_3_loss: 0.1073 - val_out_4_loss: 0.1084 - val_out_5_loss: 0.0772 - val_out_6_loss: 0.0930 - val_out_7_loss: 0.1613 - val_out_8_loss: 0.1057 - val_out_9_loss: 0.1033 - val_final_output_loss: 1.9762 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 147/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.8783 - out_0_loss: 0.2806 - out_1_loss: 0.2777 - out_2_loss: 0.2943 - out_3_loss: 0.3349 - out_4_loss: 0.2694 - out_5_loss: 0.2744 - out_6_loss: 0.2445 - out_7_loss: 0.2429 - out_8_loss: 0.2932 - out_9_loss: 0.2614 - final_output_loss: 4.1050 - out_0_acc: 6.9344e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 5.8676e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1239 - val_loss: 3.0161 - val_out_0_loss: 0.0932 - val_out_1_loss: 0.0715 - val_out_2_loss: 0.0896 - val_out_3_loss: 0.1238 - val_out_4_loss: 0.0948 - val_out_5_loss: 0.0923 - val_out_6_loss: 0.1008 - val_out_7_loss: 0.1527 - val_out_8_loss: 0.1300 - val_out_9_loss: 0.0903 - val_final_output_loss: 1.9771 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 148/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.8525 - out_0_loss: 0.2794 - out_1_loss: 0.2723 - out_2_loss: 0.2901 - out_3_loss: 0.3281 - out_4_loss: 0.2700 - out_5_loss: 0.2703 - out_6_loss: 0.2416 - out_7_loss: 0.2465 - out_8_loss: 0.2887 - out_9_loss: 0.2585 - final_output_loss: 4.1070 - out_0_acc: 8.0013e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 8.0013e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1224 - val_loss: 2.8828 - val_out_0_loss: 0.0776 - val_out_1_loss: 0.0579 - val_out_2_loss: 0.0713 - val_out_3_loss: 0.1071 - val_out_4_loss: 0.0750 - val_out_5_loss: 0.0642 - val_out_6_loss: 0.0896 - val_out_7_loss: 0.1347 - val_out_8_loss: 0.0888 - val_out_9_loss: 0.0912 - val_final_output_loss: 2.0255 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 149/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.8630 - out_0_loss: 0.2783 - out_1_loss: 0.2740 - out_2_loss: 0.2893 - out_3_loss: 0.3304 - out_4_loss: 0.2661 - out_5_loss: 0.2726 - out_6_loss: 0.2400 - out_7_loss: 0.2410 - out_8_loss: 0.2889 - out_9_loss: 0.2599 - final_output_loss: 4.1225 - out_0_acc: 6.9344e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1359 - val_loss: 2.9468 - val_out_0_loss: 0.1012 - val_out_1_loss: 0.0744 - val_out_2_loss: 0.0715 - val_out_3_loss: 0.1101 - val_out_4_loss: 0.0960 - val_out_5_loss: 0.0620 - val_out_6_loss: 0.0847 - val_out_7_loss: 0.1462 - val_out_8_loss: 0.1049 - val_out_9_loss: 0.1059 - val_final_output_loss: 1.9899 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 150/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.8143 - out_0_loss: 0.2755 - out_1_loss: 0.2695 - out_2_loss: 0.2886 - out_3_loss: 0.3250 - out_4_loss: 0.2637 - out_5_loss: 0.2695 - out_6_loss: 0.2385 - out_7_loss: 0.2413 - out_8_loss: 0.2865 - out_9_loss: 0.2586 - final_output_loss: 4.0975 - out_0_acc: 6.9344e-05 - out_1_acc: 6.4010e-05 - out_2_acc: 8.0013e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 8.0013e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1387 - val_loss: 3.0040 - val_out_0_loss: 0.1046 - val_out_1_loss: 0.0964 - val_out_2_loss: 0.0847 - val_out_3_loss: 0.1187 - val_out_4_loss: 0.1064 - val_out_5_loss: 0.0648 - val_out_6_loss: 0.0866 - val_out_7_loss: 0.1346 - val_out_8_loss: 0.1246 - val_out_9_loss: 0.1057 - val_final_output_loss: 1.9769 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2727\n",
            "Epoch 151/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.8242 - out_0_loss: 0.2713 - out_1_loss: 0.2685 - out_2_loss: 0.2861 - out_3_loss: 0.3231 - out_4_loss: 0.2671 - out_5_loss: 0.2678 - out_6_loss: 0.2350 - out_7_loss: 0.2389 - out_8_loss: 0.2829 - out_9_loss: 0.2536 - final_output_loss: 4.1301 - out_0_acc: 8.0013e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1431 - val_loss: 3.0036 - val_out_0_loss: 0.1012 - val_out_1_loss: 0.0690 - val_out_2_loss: 0.0955 - val_out_3_loss: 0.1138 - val_out_4_loss: 0.0970 - val_out_5_loss: 0.0817 - val_out_6_loss: 0.0891 - val_out_7_loss: 0.1671 - val_out_8_loss: 0.1071 - val_out_9_loss: 0.1049 - val_final_output_loss: 1.9773 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2727\n",
            "Epoch 152/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.6864 - out_0_loss: 0.2708 - out_1_loss: 0.2697 - out_2_loss: 0.2844 - out_3_loss: 0.3245 - out_4_loss: 0.2657 - out_5_loss: 0.2688 - out_6_loss: 0.2389 - out_7_loss: 0.2368 - out_8_loss: 0.2819 - out_9_loss: 0.2545 - final_output_loss: 3.9906 - out_0_acc: 8.0013e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 8.0013e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 8.0013e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1387 - val_loss: 3.1342 - val_out_0_loss: 0.1207 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.1039 - val_out_3_loss: 0.1291 - val_out_4_loss: 0.1141 - val_out_5_loss: 0.0918 - val_out_6_loss: 0.0956 - val_out_7_loss: 0.1428 - val_out_8_loss: 0.1387 - val_out_9_loss: 0.1113 - val_final_output_loss: 1.9758 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2727\n",
            "Epoch 153/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.6125 - out_0_loss: 0.2702 - out_1_loss: 0.2663 - out_2_loss: 0.2814 - out_3_loss: 0.3192 - out_4_loss: 0.2623 - out_5_loss: 0.2627 - out_6_loss: 0.2388 - out_7_loss: 0.2393 - out_8_loss: 0.2789 - out_9_loss: 0.2522 - final_output_loss: 3.9412 - out_0_acc: 7.4679e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1354 - val_loss: 2.9707 - val_out_0_loss: 0.0919 - val_out_1_loss: 0.0640 - val_out_2_loss: 0.1077 - val_out_3_loss: 0.1138 - val_out_4_loss: 0.0977 - val_out_5_loss: 0.0622 - val_out_6_loss: 0.0987 - val_out_7_loss: 0.1430 - val_out_8_loss: 0.1067 - val_out_9_loss: 0.1019 - val_final_output_loss: 1.9831 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2727\n",
            "Epoch 154/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.6028 - out_0_loss: 0.2677 - out_1_loss: 0.2633 - out_2_loss: 0.2810 - out_3_loss: 0.3174 - out_4_loss: 0.2600 - out_5_loss: 0.2649 - out_6_loss: 0.2360 - out_7_loss: 0.2380 - out_8_loss: 0.2787 - out_9_loss: 0.2520 - final_output_loss: 3.9438 - out_0_acc: 8.0013e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 8.0013e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1450 - val_loss: 2.9012 - val_out_0_loss: 0.0788 - val_out_1_loss: 0.0651 - val_out_2_loss: 0.0868 - val_out_3_loss: 0.0866 - val_out_4_loss: 0.0884 - val_out_5_loss: 0.0831 - val_out_6_loss: 0.0931 - val_out_7_loss: 0.1386 - val_out_8_loss: 0.1110 - val_out_9_loss: 0.0900 - val_final_output_loss: 1.9795 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2727\n",
            "Epoch 155/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.5648 - out_0_loss: 0.2662 - out_1_loss: 0.2623 - out_2_loss: 0.2784 - out_3_loss: 0.3179 - out_4_loss: 0.2593 - out_5_loss: 0.2613 - out_6_loss: 0.2333 - out_7_loss: 0.2342 - out_8_loss: 0.2756 - out_9_loss: 0.2551 - final_output_loss: 3.9212 - out_0_acc: 7.4679e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 8.0013e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1344 - val_loss: 2.8622 - val_out_0_loss: 0.0921 - val_out_1_loss: 0.0523 - val_out_2_loss: 0.0724 - val_out_3_loss: 0.0887 - val_out_4_loss: 0.0955 - val_out_5_loss: 0.0585 - val_out_6_loss: 0.0906 - val_out_7_loss: 0.1418 - val_out_8_loss: 0.0987 - val_out_9_loss: 0.0920 - val_final_output_loss: 1.9796 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2727\n",
            "Epoch 156/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.4425 - out_0_loss: 0.2668 - out_1_loss: 0.2635 - out_2_loss: 0.2788 - out_3_loss: 0.3165 - out_4_loss: 0.2590 - out_5_loss: 0.2598 - out_6_loss: 0.2342 - out_7_loss: 0.2348 - out_8_loss: 0.2754 - out_9_loss: 0.2499 - final_output_loss: 3.8038 - out_0_acc: 6.9344e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 6.4010e-05 - final_output_acc: 0.1368 - val_loss: 2.9940 - val_out_0_loss: 0.1076 - val_out_1_loss: 0.0857 - val_out_2_loss: 0.0944 - val_out_3_loss: 0.1166 - val_out_4_loss: 0.1231 - val_out_5_loss: 0.0890 - val_out_6_loss: 0.0760 - val_out_7_loss: 0.1346 - val_out_8_loss: 0.1098 - val_out_9_loss: 0.0863 - val_final_output_loss: 1.9708 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 157/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.6674 - out_0_loss: 0.2646 - out_1_loss: 0.2620 - out_2_loss: 0.2735 - out_3_loss: 0.3156 - out_4_loss: 0.2601 - out_5_loss: 0.2604 - out_6_loss: 0.2331 - out_7_loss: 0.2327 - out_8_loss: 0.2746 - out_9_loss: 0.2542 - final_output_loss: 4.0366 - out_0_acc: 6.9344e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 8.0013e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1339 - val_loss: 2.9913 - val_out_0_loss: 0.0938 - val_out_1_loss: 0.0746 - val_out_2_loss: 0.0797 - val_out_3_loss: 0.1197 - val_out_4_loss: 0.1235 - val_out_5_loss: 0.0879 - val_out_6_loss: 0.1069 - val_out_7_loss: 0.1392 - val_out_8_loss: 0.1111 - val_out_9_loss: 0.0886 - val_final_output_loss: 1.9663 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 158/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.4988 - out_0_loss: 0.2650 - out_1_loss: 0.2600 - out_2_loss: 0.2737 - out_3_loss: 0.3127 - out_4_loss: 0.2564 - out_5_loss: 0.2565 - out_6_loss: 0.2337 - out_7_loss: 0.2336 - out_8_loss: 0.2694 - out_9_loss: 0.2503 - final_output_loss: 3.8875 - out_0_acc: 8.0013e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1392 - val_loss: 2.9179 - val_out_0_loss: 0.0892 - val_out_1_loss: 0.0669 - val_out_2_loss: 0.0754 - val_out_3_loss: 0.0952 - val_out_4_loss: 0.1101 - val_out_5_loss: 0.0958 - val_out_6_loss: 0.0605 - val_out_7_loss: 0.1299 - val_out_8_loss: 0.1047 - val_out_9_loss: 0.1197 - val_final_output_loss: 1.9706 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 159/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.3915 - out_0_loss: 0.2617 - out_1_loss: 0.2601 - out_2_loss: 0.2707 - out_3_loss: 0.3150 - out_4_loss: 0.2538 - out_5_loss: 0.2591 - out_6_loss: 0.2343 - out_7_loss: 0.2361 - out_8_loss: 0.2678 - out_9_loss: 0.2468 - final_output_loss: 3.7861 - out_0_acc: 8.0013e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 5.8676e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.4010e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1383 - val_loss: 2.9781 - val_out_0_loss: 0.0898 - val_out_1_loss: 0.0818 - val_out_2_loss: 0.0833 - val_out_3_loss: 0.1107 - val_out_4_loss: 0.1077 - val_out_5_loss: 0.0908 - val_out_6_loss: 0.1015 - val_out_7_loss: 0.1341 - val_out_8_loss: 0.1074 - val_out_9_loss: 0.0927 - val_final_output_loss: 1.9781 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 160/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.2678 - out_0_loss: 0.2573 - out_1_loss: 0.2552 - out_2_loss: 0.2681 - out_3_loss: 0.3105 - out_4_loss: 0.2529 - out_5_loss: 0.2546 - out_6_loss: 0.2298 - out_7_loss: 0.2346 - out_8_loss: 0.2694 - out_9_loss: 0.2472 - final_output_loss: 3.6882 - out_0_acc: 8.0013e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 8.0013e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1258 - val_loss: 3.0022 - val_out_0_loss: 0.1005 - val_out_1_loss: 0.0752 - val_out_2_loss: 0.0774 - val_out_3_loss: 0.1077 - val_out_4_loss: 0.0906 - val_out_5_loss: 0.0670 - val_out_6_loss: 0.1005 - val_out_7_loss: 0.1586 - val_out_8_loss: 0.1138 - val_out_9_loss: 0.0994 - val_final_output_loss: 2.0115 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 161/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.3780 - out_0_loss: 0.2593 - out_1_loss: 0.2562 - out_2_loss: 0.2699 - out_3_loss: 0.3064 - out_4_loss: 0.2546 - out_5_loss: 0.2544 - out_6_loss: 0.2302 - out_7_loss: 0.2319 - out_8_loss: 0.2679 - out_9_loss: 0.2458 - final_output_loss: 3.8015 - out_0_acc: 7.4679e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1363 - val_loss: 2.9984 - val_out_0_loss: 0.1216 - val_out_1_loss: 0.0740 - val_out_2_loss: 0.1006 - val_out_3_loss: 0.0992 - val_out_4_loss: 0.1029 - val_out_5_loss: 0.0658 - val_out_6_loss: 0.1065 - val_out_7_loss: 0.1315 - val_out_8_loss: 0.0942 - val_out_9_loss: 0.0939 - val_final_output_loss: 2.0084 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 162/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.3956 - out_0_loss: 0.2556 - out_1_loss: 0.2544 - out_2_loss: 0.2678 - out_3_loss: 0.3070 - out_4_loss: 0.2512 - out_5_loss: 0.2518 - out_6_loss: 0.2289 - out_7_loss: 0.2346 - out_8_loss: 0.2654 - out_9_loss: 0.2456 - final_output_loss: 3.8330 - out_0_acc: 6.9344e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1325 - val_loss: 3.0090 - val_out_0_loss: 0.0922 - val_out_1_loss: 0.0577 - val_out_2_loss: 0.0726 - val_out_3_loss: 0.1113 - val_out_4_loss: 0.1081 - val_out_5_loss: 0.0920 - val_out_6_loss: 0.0966 - val_out_7_loss: 0.1615 - val_out_8_loss: 0.1254 - val_out_9_loss: 0.0884 - val_final_output_loss: 2.0031 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 163/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.3203 - out_0_loss: 0.2558 - out_1_loss: 0.2551 - out_2_loss: 0.2642 - out_3_loss: 0.3030 - out_4_loss: 0.2506 - out_5_loss: 0.2524 - out_6_loss: 0.2273 - out_7_loss: 0.2327 - out_8_loss: 0.2628 - out_9_loss: 0.2447 - final_output_loss: 3.7716 - out_0_acc: 7.4679e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1200 - val_loss: 2.9331 - val_out_0_loss: 0.0920 - val_out_1_loss: 0.0861 - val_out_2_loss: 0.1091 - val_out_3_loss: 0.1064 - val_out_4_loss: 0.1055 - val_out_5_loss: 0.0651 - val_out_6_loss: 0.0808 - val_out_7_loss: 0.1295 - val_out_8_loss: 0.0796 - val_out_9_loss: 0.0821 - val_final_output_loss: 1.9968 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 164/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.2438 - out_0_loss: 0.2568 - out_1_loss: 0.2510 - out_2_loss: 0.2645 - out_3_loss: 0.3003 - out_4_loss: 0.2489 - out_5_loss: 0.2514 - out_6_loss: 0.2257 - out_7_loss: 0.2330 - out_8_loss: 0.2597 - out_9_loss: 0.2419 - final_output_loss: 3.7105 - out_0_acc: 7.4679e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 8.0013e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 5.8676e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1344 - val_loss: 2.9470 - val_out_0_loss: 0.0956 - val_out_1_loss: 0.0679 - val_out_2_loss: 0.0672 - val_out_3_loss: 0.0955 - val_out_4_loss: 0.1005 - val_out_5_loss: 0.0921 - val_out_6_loss: 0.0824 - val_out_7_loss: 0.1418 - val_out_8_loss: 0.1056 - val_out_9_loss: 0.1059 - val_final_output_loss: 1.9924 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 165/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.4015 - out_0_loss: 0.2554 - out_1_loss: 0.2525 - out_2_loss: 0.2631 - out_3_loss: 0.2976 - out_4_loss: 0.2514 - out_5_loss: 0.2502 - out_6_loss: 0.2244 - out_7_loss: 0.2311 - out_8_loss: 0.2556 - out_9_loss: 0.2447 - final_output_loss: 3.8756 - out_0_acc: 6.4010e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 8.0013e-05 - out_3_acc: 8.0013e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1234 - val_loss: 2.9171 - val_out_0_loss: 0.0894 - val_out_1_loss: 0.0701 - val_out_2_loss: 0.0742 - val_out_3_loss: 0.1038 - val_out_4_loss: 0.0898 - val_out_5_loss: 0.0862 - val_out_6_loss: 0.0715 - val_out_7_loss: 0.1615 - val_out_8_loss: 0.0872 - val_out_9_loss: 0.0871 - val_final_output_loss: 1.9964 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.2273\n",
            "Epoch 166/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.2620 - out_0_loss: 0.2514 - out_1_loss: 0.2485 - out_2_loss: 0.2625 - out_3_loss: 0.3014 - out_4_loss: 0.2497 - out_5_loss: 0.2500 - out_6_loss: 0.2272 - out_7_loss: 0.2301 - out_8_loss: 0.2583 - out_9_loss: 0.2424 - final_output_loss: 3.7406 - out_0_acc: 8.0013e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 6.4010e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1359 - val_loss: 3.0685 - val_out_0_loss: 0.0972 - val_out_1_loss: 0.0816 - val_out_2_loss: 0.0952 - val_out_3_loss: 0.1227 - val_out_4_loss: 0.1265 - val_out_5_loss: 0.0749 - val_out_6_loss: 0.0946 - val_out_7_loss: 0.1461 - val_out_8_loss: 0.1073 - val_out_9_loss: 0.1183 - val_final_output_loss: 2.0041 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 167/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.1359 - out_0_loss: 0.2528 - out_1_loss: 0.2484 - out_2_loss: 0.2561 - out_3_loss: 0.2968 - out_4_loss: 0.2508 - out_5_loss: 0.2467 - out_6_loss: 0.2261 - out_7_loss: 0.2292 - out_8_loss: 0.2567 - out_9_loss: 0.2451 - final_output_loss: 3.6272 - out_0_acc: 7.4679e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 6.9344e-05 - out_3_acc: 6.4010e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1315 - val_loss: 2.9401 - val_out_0_loss: 0.1024 - val_out_1_loss: 0.0653 - val_out_2_loss: 0.0772 - val_out_3_loss: 0.1135 - val_out_4_loss: 0.1122 - val_out_5_loss: 0.0791 - val_out_6_loss: 0.0942 - val_out_7_loss: 0.1286 - val_out_8_loss: 0.0888 - val_out_9_loss: 0.0851 - val_final_output_loss: 1.9937 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 168/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.2463 - out_0_loss: 0.2498 - out_1_loss: 0.2496 - out_2_loss: 0.2619 - out_3_loss: 0.2994 - out_4_loss: 0.2490 - out_5_loss: 0.2450 - out_6_loss: 0.2225 - out_7_loss: 0.2294 - out_8_loss: 0.2549 - out_9_loss: 0.2445 - final_output_loss: 3.7404 - out_0_acc: 7.4679e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 8.0013e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 6.9344e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 8.0013e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1383 - val_loss: 3.0034 - val_out_0_loss: 0.0959 - val_out_1_loss: 0.0768 - val_out_2_loss: 0.0928 - val_out_3_loss: 0.1007 - val_out_4_loss: 0.1168 - val_out_5_loss: 0.0887 - val_out_6_loss: 0.0953 - val_out_7_loss: 0.1480 - val_out_8_loss: 0.1048 - val_out_9_loss: 0.0971 - val_final_output_loss: 1.9866 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 169/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 5.8819 - out_0_loss: 0.2476 - out_1_loss: 0.2451 - out_2_loss: 0.2588 - out_3_loss: 0.2941 - out_4_loss: 0.2458 - out_5_loss: 0.2479 - out_6_loss: 0.2240 - out_7_loss: 0.2261 - out_8_loss: 0.2559 - out_9_loss: 0.2418 - final_output_loss: 3.3948 - out_0_acc: 8.0013e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 8.0013e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1339 - val_loss: 2.9897 - val_out_0_loss: 0.0970 - val_out_1_loss: 0.0692 - val_out_2_loss: 0.1011 - val_out_3_loss: 0.1010 - val_out_4_loss: 0.1088 - val_out_5_loss: 0.0978 - val_out_6_loss: 0.1004 - val_out_7_loss: 0.1457 - val_out_8_loss: 0.1026 - val_out_9_loss: 0.0858 - val_final_output_loss: 1.9802 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 170/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.2143 - out_0_loss: 0.2433 - out_1_loss: 0.2492 - out_2_loss: 0.2557 - out_3_loss: 0.2961 - out_4_loss: 0.2472 - out_5_loss: 0.2463 - out_6_loss: 0.2221 - out_7_loss: 0.2269 - out_8_loss: 0.2523 - out_9_loss: 0.2413 - final_output_loss: 3.7340 - out_0_acc: 8.0013e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 8.0013e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 8.0013e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1315 - val_loss: 2.8921 - val_out_0_loss: 0.0946 - val_out_1_loss: 0.0547 - val_out_2_loss: 0.0811 - val_out_3_loss: 0.1164 - val_out_4_loss: 0.0982 - val_out_5_loss: 0.0825 - val_out_6_loss: 0.0862 - val_out_7_loss: 0.1358 - val_out_8_loss: 0.0904 - val_out_9_loss: 0.0758 - val_final_output_loss: 1.9763 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 171/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 5.9333 - out_0_loss: 0.2470 - out_1_loss: 0.2481 - out_2_loss: 0.2515 - out_3_loss: 0.2899 - out_4_loss: 0.2421 - out_5_loss: 0.2432 - out_6_loss: 0.2237 - out_7_loss: 0.2278 - out_8_loss: 0.2495 - out_9_loss: 0.2422 - final_output_loss: 3.4684 - out_0_acc: 8.0013e-05 - out_1_acc: 6.9344e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1311 - val_loss: 2.9178 - val_out_0_loss: 0.1043 - val_out_1_loss: 0.0709 - val_out_2_loss: 0.0776 - val_out_3_loss: 0.0942 - val_out_4_loss: 0.1039 - val_out_5_loss: 0.0712 - val_out_6_loss: 0.0826 - val_out_7_loss: 0.1336 - val_out_8_loss: 0.0959 - val_out_9_loss: 0.1102 - val_final_output_loss: 1.9733 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 172/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 5.9597 - out_0_loss: 0.2458 - out_1_loss: 0.2445 - out_2_loss: 0.2513 - out_3_loss: 0.2913 - out_4_loss: 0.2442 - out_5_loss: 0.2425 - out_6_loss: 0.2205 - out_7_loss: 0.2287 - out_8_loss: 0.2503 - out_9_loss: 0.2452 - final_output_loss: 3.4953 - out_0_acc: 8.0013e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 8.0013e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 6.9344e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1407 - val_loss: 2.9703 - val_out_0_loss: 0.1076 - val_out_1_loss: 0.0733 - val_out_2_loss: 0.0848 - val_out_3_loss: 0.1222 - val_out_4_loss: 0.1089 - val_out_5_loss: 0.0818 - val_out_6_loss: 0.0892 - val_out_7_loss: 0.1399 - val_out_8_loss: 0.0886 - val_out_9_loss: 0.0977 - val_final_output_loss: 1.9761 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1818\n",
            "Epoch 173/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 6.1257 - out_0_loss: 0.2434 - out_1_loss: 0.2409 - out_2_loss: 0.2530 - out_3_loss: 0.2911 - out_4_loss: 0.2415 - out_5_loss: 0.2433 - out_6_loss: 0.2220 - out_7_loss: 0.2251 - out_8_loss: 0.2484 - out_9_loss: 0.2416 - final_output_loss: 3.6752 - out_0_acc: 7.4679e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 8.0013e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 6.9344e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 6.9344e-05 - final_output_acc: 0.1407 - val_loss: 3.0313 - val_out_0_loss: 0.0965 - val_out_1_loss: 0.0820 - val_out_2_loss: 0.1020 - val_out_3_loss: 0.1158 - val_out_4_loss: 0.1100 - val_out_5_loss: 0.0734 - val_out_6_loss: 0.1012 - val_out_7_loss: 0.1506 - val_out_8_loss: 0.1101 - val_out_9_loss: 0.1121 - val_final_output_loss: 1.9776 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 174/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 5.8577 - out_0_loss: 0.2404 - out_1_loss: 0.2423 - out_2_loss: 0.2516 - out_3_loss: 0.2917 - out_4_loss: 0.2407 - out_5_loss: 0.2400 - out_6_loss: 0.2200 - out_7_loss: 0.2247 - out_8_loss: 0.2444 - out_9_loss: 0.2385 - final_output_loss: 3.4234 - out_0_acc: 7.4679e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 8.0013e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 6.9344e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 8.0013e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1378 - val_loss: 2.9550 - val_out_0_loss: 0.1013 - val_out_1_loss: 0.0707 - val_out_2_loss: 0.0850 - val_out_3_loss: 0.1011 - val_out_4_loss: 0.1150 - val_out_5_loss: 0.0857 - val_out_6_loss: 0.0746 - val_out_7_loss: 0.1442 - val_out_8_loss: 0.1032 - val_out_9_loss: 0.1128 - val_final_output_loss: 1.9615 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 175/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 5.8062 - out_0_loss: 0.2386 - out_1_loss: 0.2395 - out_2_loss: 0.2511 - out_3_loss: 0.2920 - out_4_loss: 0.2394 - out_5_loss: 0.2379 - out_6_loss: 0.2157 - out_7_loss: 0.2291 - out_8_loss: 0.2470 - out_9_loss: 0.2396 - final_output_loss: 3.3762 - out_0_acc: 7.4679e-05 - out_1_acc: 8.0013e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 6.9344e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 6.9344e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1301 - val_loss: 2.8381 - val_out_0_loss: 0.0902 - val_out_1_loss: 0.0645 - val_out_2_loss: 0.0942 - val_out_3_loss: 0.1075 - val_out_4_loss: 0.0974 - val_out_5_loss: 0.0852 - val_out_6_loss: 0.0736 - val_out_7_loss: 0.1187 - val_out_8_loss: 0.0759 - val_out_9_loss: 0.0766 - val_final_output_loss: 1.9543 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 176/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 5.8364 - out_0_loss: 0.2405 - out_1_loss: 0.2392 - out_2_loss: 0.2490 - out_3_loss: 0.2839 - out_4_loss: 0.2398 - out_5_loss: 0.2392 - out_6_loss: 0.2209 - out_7_loss: 0.2280 - out_8_loss: 0.2465 - out_9_loss: 0.2382 - final_output_loss: 3.4114 - out_0_acc: 8.0013e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 7.4679e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 7.4679e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 8.0013e-05 - out_8_acc: 8.0013e-05 - out_9_acc: 8.0013e-05 - final_output_acc: 0.1296 - val_loss: 2.9961 - val_out_0_loss: 0.1065 - val_out_1_loss: 0.0569 - val_out_2_loss: 0.1132 - val_out_3_loss: 0.1109 - val_out_4_loss: 0.1184 - val_out_5_loss: 0.0938 - val_out_6_loss: 0.0834 - val_out_7_loss: 0.1324 - val_out_8_loss: 0.1129 - val_out_9_loss: 0.1132 - val_final_output_loss: 1.9544 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 177/30000\n",
            "2083/2083 [==============================] - 9s 4ms/step - loss: 5.7945 - out_0_loss: 0.2402 - out_1_loss: 0.2412 - out_2_loss: 0.2483 - out_3_loss: 0.2865 - out_4_loss: 0.2397 - out_5_loss: 0.2373 - out_6_loss: 0.2171 - out_7_loss: 0.2233 - out_8_loss: 0.2457 - out_9_loss: 0.2379 - final_output_loss: 3.3771 - out_0_acc: 7.4679e-05 - out_1_acc: 7.4679e-05 - out_2_acc: 8.0013e-05 - out_3_acc: 7.4679e-05 - out_4_acc: 7.4679e-05 - out_5_acc: 8.0013e-05 - out_6_acc: 7.4679e-05 - out_7_acc: 7.4679e-05 - out_8_acc: 7.4679e-05 - out_9_acc: 7.4679e-05 - final_output_acc: 0.1234 - val_loss: 2.9783 - val_out_0_loss: 0.1176 - val_out_1_loss: 0.0843 - val_out_2_loss: 0.0875 - val_out_3_loss: 0.1260 - val_out_4_loss: 0.1010 - val_out_5_loss: 0.0818 - val_out_6_loss: 0.0810 - val_out_7_loss: 0.1515 - val_out_8_loss: 0.0965 - val_out_9_loss: 0.0953 - val_final_output_loss: 1.9558 - val_out_0_acc: 0.0000e+00 - val_out_1_acc: 0.0000e+00 - val_out_2_acc: 0.0000e+00 - val_out_3_acc: 0.0000e+00 - val_out_4_acc: 0.0000e+00 - val_out_5_acc: 0.0000e+00 - val_out_6_acc: 0.0000e+00 - val_out_7_acc: 0.0000e+00 - val_out_8_acc: 0.0000e+00 - val_out_9_acc: 0.0000e+00 - val_final_output_acc: 0.1364\n",
            "Epoch 178/30000\n",
            "1500/2083 [====================>.........] - ETA: 2s - loss: 5.8470 - out_0_loss: 0.2399 - out_1_loss: 0.2470 - out_2_loss: 0.2508 - out_3_loss: 0.2854 - out_4_loss: 0.2401 - out_5_loss: 0.2429 - out_6_loss: 0.2198 - out_7_loss: 0.2240 - out_8_loss: 0.2441 - out_9_loss: 0.2363 - final_output_loss: 3.4166 - out_0_acc: 1.1111e-04 - out_1_acc: 7.4074e-05 - out_2_acc: 8.1481e-05 - out_3_acc: 5.9259e-05 - out_4_acc: 8.1481e-05 - out_5_acc: 6.6667e-05 - out_6_acc: 8.1481e-05 - out_7_acc: 5.9259e-05 - out_8_acc: 6.6667e-05 - out_9_acc: 6.6667e-05 - final_output_acc: 0.1340"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3OOmiG0OSWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_model(model_train,show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4A1XXe0Lq6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#打開Ngrolk並綁定port:6006\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "\"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o-ZUWuct1Qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "function ConnectButton(){\n",
        "    console.log(\"Connect pushed\"); \n",
        "    document.querySelector(\"#connect\").click() \n",
        "}\n",
        "setInterval(ConnectButton,60000);"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}